{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e3ab754",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70347d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8463450d",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2061aa",
   "metadata": {},
   "source": [
    "Linear Regression is a linear machine learning model that assumes a linear relationship between the input variables (x) and the single output variable (y). It uses this information to predict the value of y based on the value of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84814161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "from sklearn.linear_model import LinearRegression #Linear regression package\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b5aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing a dataset for linear regression\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "X = boston['data']\n",
    "y = boston['target']\n",
    "# Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8ef0529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax for creating a Linear Regression model\n",
    "\n",
    "# LinearRegression(*, fit_intercept=True, copy_X=True, n_jobs=None, positive=False)\n",
    "\n",
    "# fit_intercept - calculate the y-intercept of the model\n",
    "# copy_X - Changes the value of x entered in the model\n",
    "# positive - forces the coefficients to be positive\n",
    "\n",
    "#Simple model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a122e49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  [[6.72400e-02 0.00000e+00 3.24000e+00 ... 1.69000e+01 3.75210e+02\n",
      "  7.34000e+00]\n",
      " [9.23230e+00 0.00000e+00 1.81000e+01 ... 2.02000e+01 3.66150e+02\n",
      "  9.53000e+00]\n",
      " [1.14250e-01 0.00000e+00 1.38900e+01 ... 1.64000e+01 3.93740e+02\n",
      "  1.05000e+01]\n",
      " ...\n",
      " [1.68118e+01 0.00000e+00 1.81000e+01 ... 2.02000e+01 3.96900e+02\n",
      "  3.08100e+01]\n",
      " [4.92980e-01 0.00000e+00 9.90000e+00 ... 1.84000e+01 3.96900e+02\n",
      "  4.54000e+00]\n",
      " [2.98500e-02 0.00000e+00 2.18000e+00 ... 1.87000e+01 3.94120e+02\n",
      "  5.21000e+00]]\n",
      "Expected output :  [22.6 50.  23.   8.3 21.2 19.9 20.6 18.7 16.1 18.6  8.8 17.2 14.9 10.5\n",
      " 50.  29.  23.  33.3 29.4 21.  23.8 19.1 20.4 29.1 19.3 23.1 19.6 19.4\n",
      " 38.7 18.7 14.6 20.  20.5 20.1 23.6 16.8  5.6 50.  14.5 13.3 23.9 20.\n",
      " 19.8 13.8 16.5 21.6 20.3 17.  11.8 27.5 15.6 23.1 24.3 42.8 15.6 21.7\n",
      " 17.1 17.2 15.  21.7 18.6 21.  33.1 31.5 20.1 29.8 15.2 15.  27.5 22.6\n",
      " 20.  21.4 23.5 31.2 23.7  7.4 48.3 24.4 22.6 18.3 23.3 17.1 27.9 44.8\n",
      " 50.  23.  21.4 10.2 23.3 23.2 18.9 13.4 21.9 24.8 11.9 24.3 13.8 24.7\n",
      " 14.1 18.7 28.1 19.8 26.7 21.7 22.  22.9 10.4 21.9 20.6 26.4 41.3 17.2\n",
      " 27.1 20.4 16.5 24.4  8.4 23.   9.7 50.  30.5 12.3 19.4 21.2 20.3 18.8\n",
      " 33.4 18.5 19.6 33.2 13.1  7.5 13.6 17.4  8.4 35.4 24.  13.4 26.2  7.2\n",
      " 13.1 24.5 37.2 25.  24.1 16.6 32.9 36.2 11.   7.2 22.8 28.7]\n",
      "Predicted output :  [24.9357079  23.75163164 29.32638296 11.97534566 21.37272478 19.19148525\n",
      " 20.5717479  21.21154015 19.04572003 20.35463238  5.44119126 16.93688709\n",
      " 17.15482272  5.3928209  40.20270696 32.31327348 22.46213268 36.50124666\n",
      " 31.03737014 23.17124551 24.74815321 24.49939403 20.6595791  30.4547583\n",
      " 22.32487164 10.18932894 17.44286422 18.26103077 35.63299326 20.81960303\n",
      " 18.27218007 17.72047628 19.33772473 23.62254823 28.97766856 19.45036239\n",
      " 11.13170639 24.81843595 18.05294835 15.59712226 26.21043403 20.81140432\n",
      " 22.17349382 15.48367365 22.62261604 24.88561528 19.74754478 23.0465628\n",
      "  9.84579105 24.36378793 21.47849008 17.62118176 24.39160873 29.95102691\n",
      " 13.57219422 21.53645439 20.53306273 15.03433182 14.3232289  22.11929299\n",
      " 17.07321915 21.54141094 32.96766968 31.371599   17.7860591  32.75069556\n",
      " 18.74795323 19.21428022 19.41970047 23.08087809 22.87732816 24.06399098\n",
      " 30.52824406 28.71453508 25.90763165  5.17596718 36.8709072  23.76983849\n",
      " 27.26064379 19.25849042 28.41860517 19.3008798  18.94922353 38.00154059\n",
      " 39.44096748 23.72297885 24.83722534 16.52015743 25.9970546  16.73997072\n",
      " 15.48656983 13.52825536 24.12884363 30.76919578 22.18731163 19.8848644\n",
      "  0.42275479 24.86785849 16.05692    17.42486412 25.49798527 22.35171315\n",
      " 32.66562689 22.04428746 27.29799885 23.20302026  6.86196574 14.869251\n",
      " 22.31804948 29.18125768 33.22568234 13.24392523 19.67195771 20.7502616\n",
      " 12.02271319 23.50067006  5.55662571 19.87634689  9.27059783 44.81787339\n",
      " 30.56017983 12.44394048 17.33192202 21.48313292 23.52664913 20.49877266\n",
      " 35.09161099 13.22639935 20.70321163 35.35582833 19.45050576 13.81603561\n",
      " 14.15654562 23.03678503 15.07521258 30.9662041  25.23236632 15.43763716\n",
      " 24.06406534  9.93080346 15.01618901 21.06098873 32.87115732 27.80927747\n",
      " 25.91293794 15.27877362 30.97489404 27.81107682 14.5068157   7.57369946\n",
      " 28.3348068  25.04341153]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the input & output\n",
    "\n",
    "# Input: A two-dimensional array which contains all the features of the boston housing dataset\n",
    "print(\"Input : \", X_test)\n",
    "\n",
    "# Output: The ouput array is the prediction\n",
    "print(\"Expected output : \", y_test)\n",
    "print(\"Predicted output : \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dd211c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 27.195965766883205\n",
      "Root Mean Squared Error: 5.214975145375403\n",
      "R^2 Score: 0.6733825506400195\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Accuracy\n",
    "# Accuracy of a linear model can't be calculated, the accuracy is predicted using error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Mean Squared Error\n",
    "print(\"Mean Squared Error:\",mean_squared_error(y_test, y_pred)) # tells you how close a regression line is to a set of points\n",
    "# squaring is necessary to remove any negative signs\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(\"Root Mean Squared Error:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "\n",
    "# R2 Score\n",
    "print(\"R^2 Score:\", r2_score(y_test,y_pred)) # correlation between actual and predicted value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d53dfc",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc3168",
   "metadata": {},
   "source": [
    "Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd1515bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required packages\n",
    "from sklearn.linear_model import LogisticRegression #Logistic regression package\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbfe7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing a dataset for logistic regression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer[\"data\"]\n",
    "y = cancer['target']\n",
    "#Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88f46c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Syntax for creating a Logistic Regression model\n",
    "\n",
    "# LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, \n",
    "# intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, \n",
    "# multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "\n",
    "# Link for explanation of terms : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "#Simple model\n",
    "logreg = LogisticRegression(max_iter=3000) \n",
    "logreg.fit(X_train,y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "818db063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  [[1.161e+01 1.602e+01 7.546e+01 ... 1.105e-01 2.787e-01 7.427e-02]\n",
      " [1.029e+01 2.761e+01 6.567e+01 ... 9.127e-02 2.226e-01 8.283e-02]\n",
      " [1.571e+01 1.393e+01 1.020e+02 ... 1.374e-01 2.723e-01 7.071e-02]\n",
      " ...\n",
      " [1.236e+01 2.180e+01 7.978e+01 ... 1.205e-01 2.972e-01 9.261e-02]\n",
      " [1.902e+01 2.459e+01 1.220e+02 ... 1.956e-01 3.956e-01 9.288e-02]\n",
      " [1.239e+01 1.748e+01 8.064e+01 ... 9.804e-02 2.819e-01 1.118e-01]]\n",
      "Expected output :  [1 1 1 0 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0\n",
      " 0 0 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 0 0 0\n",
      " 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1\n",
      " 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 0 1 0 1]\n",
      "Predicted output :  [1 1 1 0 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0\n",
      " 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1\n",
      " 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the input & output\n",
    "\n",
    "# Input: A two-dimensional array which contains all the features of the boston housing dataset\n",
    "print(\"Input : \", X_test)\n",
    "\n",
    "# Output: The ouput array is the prediction\n",
    "print(\"Expected output : \", y_test)\n",
    "print(\"Predicted output : \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b5976ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score: 0.9649122807017544\n",
      "Mean Squared Error: 0.03508771929824561\n",
      "Root Mean Squared Error: 0.1873171623163388\n",
      "R^2 value 0.8527554535017221\n",
      "Precision: 0.9622641509433962\n",
      "Recall: 0.9807692307692307\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Accuracy\n",
    "# Importing necessary packages\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Accuracy\n",
    "print(\"Test Accuracy Score:\", logreg.score(X_test, y_test)) #Predicted correctly/Total values\n",
    "\n",
    "# Mean Squared Error\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))# tells you how close a regression line is to a set of points\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(\"Root Mean Squared Error:\", mean_squared_error(y_test, y_pred, squared=False)) \n",
    "\n",
    "# R2 Score\n",
    "print(\"R^2 value\", r2_score(y_test,y_pred)) # correlation between actual and predicted value\n",
    "\n",
    "# Precision\n",
    "print(\"Precision:\",precision_score(y_test, y_pred)) #Proportion of positive identifications actually correct\n",
    "\n",
    "# Recall\n",
    "print(\"Recall:\",recall_score(y_test, y_pred)) # Proportion of actual positives was identified correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb4e4a6",
   "metadata": {},
   "source": [
    "## Decision Tree 1 - Iterative Dichotomiser 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6925d85b",
   "metadata": {},
   "source": [
    "A decision tree is a structure that contains nodes (rectangular boxes) and edges(arrows) and is built from a dataset (with rows and columns). Each node is used to make a decision (decision node) or represent an outcome (leaf node)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d70d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required packages\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree Classifier package\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c58d5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing a dataset for Decision Tree 1 - Iterative Dichotomiser 3\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "#Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f16bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Syntax for creating a Decision Tree 1 - Iterative Dichotomiser 3 model\n",
    "\n",
    "# DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, \n",
    "# min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, \n",
    "# max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0)\n",
    "\n",
    "# Link for explanation of terms : https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "#Simple model\n",
    "dtc = DecisionTreeClassifier(criterion='entropy',max_depth=3)\n",
    "dtc.fit(X_train, y_train)\n",
    "y_pred = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "988d11f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  [[5.  3.4 1.6 0.4]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [6.  2.2 5.  1.5]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [6.9 3.1 5.1 2.3]]\n",
      "Expected output :  [0 0 2 2 1 2 0 1 2 0 2 0 2 2 2 1 2 2 0 1 2 0 0 1 1 2 0 1 2 0 2 1 2 0 0 1 0\n",
      " 2 2 1 2 0 2 0 2]\n",
      "Predicted output :  [0 0 2 2 1 2 0 1 1 0 2 0 2 2 2 1 2 2 0 1 2 0 0 1 1 2 0 1 2 0 2 1 2 0 0 1 0\n",
      " 2 1 1 2 0 2 0 2]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the input & output\n",
    "\n",
    "# Input: A two-dimensional array which contains all the features of the boston housing dataset\n",
    "print(\"Input : \", X_test)\n",
    "\n",
    "# Output: The ouput array is the prediction\n",
    "print(\"Expected output : \", y_test)\n",
    "print(\"Predicted output : \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "398268bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score: 0.9555555555555556\n",
      "Mean Squared Error: 0.044444444444444446\n",
      "Root Mean Squared Error: 0.21081851067789195\n",
      "R^2 value 0.9419354838709677\n",
      "Precision: 0.962962962962963\n",
      "Recall: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Accuracy\n",
    "# Importing necessary packages\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Accuracy\n",
    "print(\"Test Accuracy Score:\", dtc.score(X_test, y_test)) #Predicted correctly/Total values\n",
    "\n",
    "# Mean Squared Error\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))# tells you how close a regression line is to a set of points\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(\"Root Mean Squared Error:\", mean_squared_error(y_test, y_pred, squared=False)) \n",
    "\n",
    "# R2 Score\n",
    "print(\"R^2 value\", r2_score(y_test,y_pred)) # correlation between actual and predicted value\n",
    "\n",
    "# Precision\n",
    "print(\"Precision:\",precision_score(y_test, y_pred, average='weighted')) #Proportion of positive identifications actually correct\n",
    "\n",
    "# Recall\n",
    "print(\"Recall:\",recall_score(y_test, y_pred, average='weighted')) # Proportion of actual positives was identified correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b95083",
   "metadata": {},
   "source": [
    "## Decision Tree - CART (Classification and Regression Tree Algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c772e16b",
   "metadata": {},
   "source": [
    "A classification algorithm for building a decision tree based on Gini's impurity index as splitting criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f1fd460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required packages\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree Classifier package\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "140c9237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing a dataset for Decision Tree 2 - CART\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "#Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "248f7335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Syntax for creating a Decision Tree 1 - Iterative Dichotomiser 3 model\n",
    "\n",
    "# DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, \n",
    "# min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, \n",
    "# max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0)\n",
    "\n",
    "# Link for explanation of terms : https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "#Simple model\n",
    "dtc_gini = DecisionTreeClassifier(criterion='gini',max_depth=3)\n",
    "dtc_gini.fit(X_train, y_train)\n",
    "y_pred = dtc_gini.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5872c4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  [[6.4 3.2 4.5 1.5]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [6.7 3.3 5.7 2.5]]\n",
      "Expected output :  [1 1 1 2 0 0 1 2 0 2 0 0 0 2 2 2 0 1 2 0 0 1 0 0 1 2 1 0 2 2 0 1 0 1 2 0 2\n",
      " 2 2 0 1 2 1 0 2]\n",
      "Predicted output :  [1 1 1 2 0 0 1 2 0 2 0 0 0 2 2 1 0 1 2 0 0 1 0 0 1 2 1 0 2 2 0 1 0 1 2 0 1\n",
      " 2 2 0 1 2 1 0 2]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the input & output\n",
    "\n",
    "# Input: A two-dimensional array which contains all the features of the boston housing dataset\n",
    "print(\"Input : \", X_test)\n",
    "\n",
    "# Output: The ouput array is the prediction\n",
    "print(\"Expected output : \", y_test)\n",
    "print(\"Predicted output : \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "299b24fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score: 0.9555555555555556\n",
      "Mean Squared Error: 0.044444444444444446\n",
      "Root Mean Squared Error: 0.21081851067789195\n",
      "R^2 value 0.9393530997304582\n",
      "Precision: 0.9619047619047619\n",
      "Recall: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Accuracy\n",
    "# Importing necessary packages\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Accuracy\n",
    "print(\"Test Accuracy Score:\", dtc.score(X_test, y_test)) #Predicted correctly/Total values\n",
    "\n",
    "# Mean Squared Error\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))# tells you how close a regression line is to a set of points\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(\"Root Mean Squared Error:\", mean_squared_error(y_test, y_pred, squared=False)) \n",
    "\n",
    "# R2 Score\n",
    "print(\"R^2 value\", r2_score(y_test,y_pred)) # correlation between actual and predicted value\n",
    "\n",
    "# Precision\n",
    "print(\"Precision:\",precision_score(y_test, y_pred, average='weighted')) #Proportion of positive identifications actually correct\n",
    "\n",
    "# Recall\n",
    "print(\"Recall:\",recall_score(y_test, y_pred, average='weighted')) # Proportion of actual positives was identified correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428bda0a",
   "metadata": {},
   "source": [
    "## Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadaa775",
   "metadata": {},
   "source": [
    "### Type 1 - Gaussian Naive Bayes Algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd3d921",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes Algorithm is used when the features have continuous values, when the features are following a gaussian distribution i.e, normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07ea4691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47fbb843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing a dataset for Naive Bayes Algorithm\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "#Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba991857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Syntax for creating a Naive Bayes Algorithm\n",
    "\n",
    "#GaussianNB(*, priors=None, var_smoothing=1e-09)\n",
    "\n",
    "#Link for explanation of the model: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "\n",
    "#Simple model\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09fc1e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  [[5.1 3.5 1.4 0.3]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [5.  2.  3.5 1. ]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [6.3 2.7 4.9 1.8]]\n",
      "Expected output :  [0 2 1 1 2 2 0 1 0 0 1 1 0 1 0 2 1 0 0 1 1 0 0 1 0 1 1 2 2 2 1 1 0 2 1 0 2\n",
      " 0 1 1 1 1 2 2 2]\n",
      "Predicted output :  [0 2 1 1 2 2 0 1 0 0 1 1 0 1 0 2 1 0 0 1 1 0 0 1 0 1 1 2 2 2 1 1 0 2 1 0 2\n",
      " 0 1 1 1 1 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the input & output\n",
    "\n",
    "# Input: A two-dimensional array which contains all the features of the boston housing dataset\n",
    "print(\"Input : \", X_test)\n",
    "\n",
    "# Output: The ouput array is the prediction\n",
    "print(\"Expected output : \", y_test)\n",
    "print(\"Predicted output : \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aaab4860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score: 1.0\n",
      "Mean Squared Error: 0.0\n",
      "Root Mean Squared Error: 0.0\n",
      "R^2 value 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Accuracy\n",
    "# Importing necessary packages\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Accuracy\n",
    "print(\"Test Accuracy Score:\", gnb.score(X_test, y_test)) #Predicted correctly/Total values\n",
    "\n",
    "# Mean Squared Error\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))# tells you how close a regression line is to a set of points\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(\"Root Mean Squared Error:\", mean_squared_error(y_test, y_pred, squared=False)) \n",
    "\n",
    "# R2 Score\n",
    "print(\"R^2 value\", r2_score(y_test,y_pred)) # correlation between actual and predicted value\n",
    "\n",
    "# Precision\n",
    "print(\"Precision:\",precision_score(y_test, y_pred, average='weighted')) #Proportion of positive identifications actually correct\n",
    "\n",
    "# Recall\n",
    "print(\"Recall:\",recall_score(y_test, y_pred, average='weighted')) # Proportion of actual positives was identified correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ad89d0",
   "metadata": {},
   "source": [
    "## KMeans Clustering algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8d767f",
   "metadata": {},
   "source": [
    "The K-means clustering algorithm computes centroids and repeats until the optimal centroid is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73fc169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required packages\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d927e1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "5  Adelie  Torgersen            39.3           20.6              190.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "4       3450.0  Female  \n",
       "5       3650.0    Male  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload your data as a csv file and load it as a data frame \n",
    "df = pd.read_csv('penguins.csv').dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6d37ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Using the elbow method to find out the optimal number of KMeans clusters\n",
    "X = np.array(df.loc[:,['bill_length_mm','bill_depth_mm']]).reshape(-1, 2)\n",
    "\n",
    "# Determine optimal cluster number with elbow method\n",
    "wcss = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    model = KMeans(n_clusters = i,init = 'k-means++',max_iter = 300,n_init = 10,random_state = 0)\n",
    "    model.fit(X)                              \n",
    "    wcss.append(model.inertia_)\n",
    "    \n",
    "# Show Elbow plot\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('Elbow Method')                               # Set plot title\n",
    "plt.xlabel('Number of clusters')                        # Set x axis name\n",
    "plt.ylabel('Within Cluster Sum of Squares (WCSS)')      # Set y axis name\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b147877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Syntax for creating a KMeans Clustering Algorithm\n",
    "\n",
    "#KMeans(n_clusters=8, *, init='k-means++', n_init=10, max_iter=300, tol=0.0001, verbose=0, random_state=None, \n",
    "#copy_x=True, algorithm='lloyd')\n",
    "\n",
    "#n_clusters - amount of clusters\n",
    "#max_iter - maximum number of iteration\n",
    "#n_init - How often algorithm will run with different centroid\n",
    "#random_state - Choose random state for reproducibility\n",
    "\n",
    "#Link for explanation of the model: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "\n",
    "#Simple model\n",
    "kmeans = KMeans(n_clusters = 3,max_iter = 300,n_init = 10,random_state = 0)    \n",
    "y_pred = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab8046b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  [[39.1 18.7]\n",
      " [39.5 17.4]\n",
      " [40.3 18. ]\n",
      " [36.7 19.3]\n",
      " [39.3 20.6]\n",
      " [38.9 17.8]\n",
      " [39.2 19.6]\n",
      " [41.1 17.6]\n",
      " [38.6 21.2]\n",
      " [34.6 21.1]\n",
      " [36.6 17.8]\n",
      " [38.7 19. ]\n",
      " [42.5 20.7]\n",
      " [34.4 18.4]\n",
      " [46.  21.5]\n",
      " [37.8 18.3]\n",
      " [37.7 18.7]\n",
      " [35.9 19.2]\n",
      " [38.2 18.1]\n",
      " [38.8 17.2]\n",
      " [35.3 18.9]\n",
      " [40.6 18.6]\n",
      " [40.5 17.9]\n",
      " [37.9 18.6]\n",
      " [40.5 18.9]\n",
      " [39.5 16.7]\n",
      " [37.2 18.1]\n",
      " [39.5 17.8]\n",
      " [40.9 18.9]\n",
      " [36.4 17. ]\n",
      " [39.2 21.1]\n",
      " [38.8 20. ]\n",
      " [42.2 18.5]\n",
      " [37.6 19.3]\n",
      " [39.8 19.1]\n",
      " [36.5 18. ]\n",
      " [40.8 18.4]\n",
      " [36.  18.5]\n",
      " [44.1 19.7]\n",
      " [37.  16.9]\n",
      " [39.6 18.8]\n",
      " [41.1 19. ]\n",
      " [36.  17.9]\n",
      " [42.3 21.2]\n",
      " [39.6 17.7]\n",
      " [40.1 18.9]\n",
      " [35.  17.9]\n",
      " [42.  19.5]\n",
      " [34.5 18.1]\n",
      " [41.4 18.6]\n",
      " [39.  17.5]\n",
      " [40.6 18.8]\n",
      " [36.5 16.6]\n",
      " [37.6 19.1]\n",
      " [35.7 16.9]\n",
      " [41.3 21.1]\n",
      " [37.6 17. ]\n",
      " [41.1 18.2]\n",
      " [36.4 17.1]\n",
      " [41.6 18. ]\n",
      " [35.5 16.2]\n",
      " [41.1 19.1]\n",
      " [35.9 16.6]\n",
      " [41.8 19.4]\n",
      " [33.5 19. ]\n",
      " [39.7 18.4]\n",
      " [39.6 17.2]\n",
      " [45.8 18.9]\n",
      " [35.5 17.5]\n",
      " [42.8 18.5]\n",
      " [40.9 16.8]\n",
      " [37.2 19.4]\n",
      " [36.2 16.1]\n",
      " [42.1 19.1]\n",
      " [34.6 17.2]\n",
      " [42.9 17.6]\n",
      " [36.7 18.8]\n",
      " [35.1 19.4]\n",
      " [37.3 17.8]\n",
      " [41.3 20.3]\n",
      " [36.3 19.5]\n",
      " [36.9 18.6]\n",
      " [38.3 19.2]\n",
      " [38.9 18.8]\n",
      " [35.7 18. ]\n",
      " [41.1 18.1]\n",
      " [34.  17.1]\n",
      " [39.6 18.1]\n",
      " [36.2 17.3]\n",
      " [40.8 18.9]\n",
      " [38.1 18.6]\n",
      " [40.3 18.5]\n",
      " [33.1 16.1]\n",
      " [43.2 18.5]\n",
      " [35.  17.9]\n",
      " [41.  20. ]\n",
      " [37.7 16. ]\n",
      " [37.8 20. ]\n",
      " [37.9 18.6]\n",
      " [39.7 18.9]\n",
      " [38.6 17.2]\n",
      " [38.2 20. ]\n",
      " [38.1 17. ]\n",
      " [43.2 19. ]\n",
      " [38.1 16.5]\n",
      " [45.6 20.3]\n",
      " [39.7 17.7]\n",
      " [42.2 19.5]\n",
      " [39.6 20.7]\n",
      " [42.7 18.3]\n",
      " [38.6 17. ]\n",
      " [37.3 20.5]\n",
      " [35.7 17. ]\n",
      " [41.1 18.6]\n",
      " [36.2 17.2]\n",
      " [37.7 19.8]\n",
      " [40.2 17. ]\n",
      " [41.4 18.5]\n",
      " [35.2 15.9]\n",
      " [40.6 19. ]\n",
      " [38.8 17.6]\n",
      " [41.5 18.3]\n",
      " [39.  17.1]\n",
      " [44.1 18. ]\n",
      " [38.5 17.9]\n",
      " [43.1 19.2]\n",
      " [36.8 18.5]\n",
      " [37.5 18.5]\n",
      " [38.1 17.6]\n",
      " [41.1 17.5]\n",
      " [35.6 17.5]\n",
      " [40.2 20.1]\n",
      " [37.  16.5]\n",
      " [39.7 17.9]\n",
      " [40.2 17.1]\n",
      " [40.6 17.2]\n",
      " [32.1 15.5]\n",
      " [40.7 17. ]\n",
      " [37.3 16.8]\n",
      " [39.  18.7]\n",
      " [39.2 18.6]\n",
      " [36.6 18.4]\n",
      " [36.  17.8]\n",
      " [37.8 18.1]\n",
      " [36.  17.1]\n",
      " [41.5 18.5]\n",
      " [46.5 17.9]\n",
      " [50.  19.5]\n",
      " [51.3 19.2]\n",
      " [45.4 18.7]\n",
      " [52.7 19.8]\n",
      " [45.2 17.8]\n",
      " [46.1 18.2]\n",
      " [51.3 18.2]\n",
      " [46.  18.9]\n",
      " [51.3 19.9]\n",
      " [46.6 17.8]\n",
      " [51.7 20.3]\n",
      " [47.  17.3]\n",
      " [52.  18.1]\n",
      " [45.9 17.1]\n",
      " [50.5 19.6]\n",
      " [50.3 20. ]\n",
      " [58.  17.8]\n",
      " [46.4 18.6]\n",
      " [49.2 18.2]\n",
      " [42.4 17.3]\n",
      " [48.5 17.5]\n",
      " [43.2 16.6]\n",
      " [50.6 19.4]\n",
      " [46.7 17.9]\n",
      " [52.  19. ]\n",
      " [50.5 18.4]\n",
      " [49.5 19. ]\n",
      " [46.4 17.8]\n",
      " [52.8 20. ]\n",
      " [40.9 16.6]\n",
      " [54.2 20.8]\n",
      " [42.5 16.7]\n",
      " [51.  18.8]\n",
      " [49.7 18.6]\n",
      " [47.5 16.8]\n",
      " [47.6 18.3]\n",
      " [52.  20.7]\n",
      " [46.9 16.6]\n",
      " [53.5 19.9]\n",
      " [49.  19.5]\n",
      " [46.2 17.5]\n",
      " [50.9 19.1]\n",
      " [45.5 17. ]\n",
      " [50.9 17.9]\n",
      " [50.8 18.5]\n",
      " [50.1 17.9]\n",
      " [49.  19.6]\n",
      " [51.5 18.7]\n",
      " [49.8 17.3]\n",
      " [48.1 16.4]\n",
      " [51.4 19. ]\n",
      " [45.7 17.3]\n",
      " [50.7 19.7]\n",
      " [42.5 17.3]\n",
      " [52.2 18.8]\n",
      " [45.2 16.6]\n",
      " [49.3 19.9]\n",
      " [50.2 18.8]\n",
      " [45.6 19.4]\n",
      " [51.9 19.5]\n",
      " [46.8 16.5]\n",
      " [45.7 17. ]\n",
      " [55.8 19.8]\n",
      " [43.5 18.1]\n",
      " [49.6 18.2]\n",
      " [50.8 19. ]\n",
      " [50.2 18.7]\n",
      " [46.1 13.2]\n",
      " [50.  16.3]\n",
      " [48.7 14.1]\n",
      " [50.  15.2]\n",
      " [47.6 14.5]\n",
      " [46.5 13.5]\n",
      " [45.4 14.6]\n",
      " [46.7 15.3]\n",
      " [43.3 13.4]\n",
      " [46.8 15.4]\n",
      " [40.9 13.7]\n",
      " [49.  16.1]\n",
      " [45.5 13.7]\n",
      " [48.4 14.6]\n",
      " [45.8 14.6]\n",
      " [49.3 15.7]\n",
      " [42.  13.5]\n",
      " [49.2 15.2]\n",
      " [46.2 14.5]\n",
      " [48.7 15.1]\n",
      " [50.2 14.3]\n",
      " [45.1 14.5]\n",
      " [46.5 14.5]\n",
      " [46.3 15.8]\n",
      " [42.9 13.1]\n",
      " [46.1 15.1]\n",
      " [47.8 15. ]\n",
      " [48.2 14.3]\n",
      " [50.  15.3]\n",
      " [47.3 15.3]\n",
      " [42.8 14.2]\n",
      " [45.1 14.5]\n",
      " [59.6 17. ]\n",
      " [49.1 14.8]\n",
      " [48.4 16.3]\n",
      " [42.6 13.7]\n",
      " [44.4 17.3]\n",
      " [44.  13.6]\n",
      " [48.7 15.7]\n",
      " [42.7 13.7]\n",
      " [49.6 16. ]\n",
      " [45.3 13.7]\n",
      " [49.6 15. ]\n",
      " [50.5 15.9]\n",
      " [43.6 13.9]\n",
      " [45.5 13.9]\n",
      " [50.5 15.9]\n",
      " [44.9 13.3]\n",
      " [45.2 15.8]\n",
      " [46.6 14.2]\n",
      " [48.5 14.1]\n",
      " [45.1 14.4]\n",
      " [50.1 15. ]\n",
      " [46.5 14.4]\n",
      " [45.  15.4]\n",
      " [43.8 13.9]\n",
      " [45.5 15. ]\n",
      " [43.2 14.5]\n",
      " [50.4 15.3]\n",
      " [45.3 13.8]\n",
      " [46.2 14.9]\n",
      " [45.7 13.9]\n",
      " [54.3 15.7]\n",
      " [45.8 14.2]\n",
      " [49.8 16.8]\n",
      " [49.5 16.2]\n",
      " [43.5 14.2]\n",
      " [50.7 15. ]\n",
      " [47.7 15. ]\n",
      " [46.4 15.6]\n",
      " [48.2 15.6]\n",
      " [46.5 14.8]\n",
      " [46.4 15. ]\n",
      " [48.6 16. ]\n",
      " [47.5 14.2]\n",
      " [51.1 16.3]\n",
      " [45.2 13.8]\n",
      " [45.2 16.4]\n",
      " [49.1 14.5]\n",
      " [52.5 15.6]\n",
      " [47.4 14.6]\n",
      " [50.  15.9]\n",
      " [44.9 13.8]\n",
      " [50.8 17.3]\n",
      " [43.4 14.4]\n",
      " [51.3 14.2]\n",
      " [47.5 14. ]\n",
      " [52.1 17. ]\n",
      " [47.5 15. ]\n",
      " [52.2 17.1]\n",
      " [45.5 14.5]\n",
      " [49.5 16.1]\n",
      " [44.5 14.7]\n",
      " [50.8 15.7]\n",
      " [49.4 15.8]\n",
      " [46.9 14.6]\n",
      " [48.4 14.4]\n",
      " [51.1 16.5]\n",
      " [48.5 15. ]\n",
      " [55.9 17. ]\n",
      " [47.2 15.5]\n",
      " [49.1 15. ]\n",
      " [46.8 16.1]\n",
      " [41.7 14.7]\n",
      " [53.4 15.8]\n",
      " [43.3 14. ]\n",
      " [48.1 15.1]\n",
      " [50.5 15.2]\n",
      " [49.8 15.9]\n",
      " [43.5 15.2]\n",
      " [51.5 16.3]\n",
      " [46.2 14.1]\n",
      " [55.1 16. ]\n",
      " [48.8 16.2]\n",
      " [47.2 13.7]\n",
      " [46.8 14.3]\n",
      " [50.4 15.7]\n",
      " [45.2 14.8]\n",
      " [49.9 16.1]]\n",
      "Class of output :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1\n",
      " 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 0\n",
      " 0 2 0 2 2 0 2 0 2 0 2 0 2 0 0 0 2 0 2 0 2 0 2 0 0 0 2 0 1 0 2 0 0 2 2 0 2\n",
      " 0 0 2 0 2 0 0 0 0 0 0 2 0 2 0 2 0 2 0 0 2 0 2 2 0 2 0 0 0 2 0 2 0 2 2 2 2\n",
      " 2 2 2 0 2 2 2 0 2 0 2 0 0 2 2 2 2 2 2 2 0 2 2 2 0 0 0 2 2 2 0 2 0 2 0 0 2\n",
      " 2 0 2 2 2 2 2 0 2 2 2 2 2 0 2 2 2 0 2 0 0 2 0 2 2 2 2 2 0 2 0 2 2 0 0 2 0\n",
      " 2 0 2 0 2 0 2 0 2 0 2 0 0 2 2 0 2 0 2 0 2 2 0 2 2 0 0 2 0 2 0 0 2 2 0 2 0]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the input & output\n",
    "\n",
    "# Input: A two-dimensional array which contains all the features of the boston housing dataset\n",
    "print(\"Input : \", X)\n",
    "\n",
    "# Output: The ouput array is the prediction\n",
    "print(\"Class of output : \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d806a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Evaluate the KMeans model using silhouette samples\n",
    "from sklearn.metrics import silhouette_samples\n",
    "for i, k in enumerate([2, 3, 4]):\n",
    "    fig, ax1 = plt.subplots(1)\n",
    "    fig.set_size_inches(18, 7)\n",
    "    \n",
    "    # Run the Kmeans algorithm\n",
    "    km = KMeans(n_clusters=k)\n",
    "    labels = km.fit_predict(X_train)\n",
    "    centroids = km.cluster_centers_\n",
    "\n",
    "    # Get silhouette samples\n",
    "    silhouette_vals = silhouette_samples(X_train, labels)\n",
    "\n",
    "    # Silhouette plot\n",
    "    y_ticks = []\n",
    "    y_lower, y_upper = 0, 0\n",
    "    for i, cluster in enumerate(np.unique(labels)):\n",
    "        cluster_silhouette_vals = silhouette_vals[labels == cluster]\n",
    "        cluster_silhouette_vals.sort()\n",
    "        y_upper += len(cluster_silhouette_vals)\n",
    "        ax1.barh(range(y_lower, y_upper), cluster_silhouette_vals, edgecolor='none', height=1)\n",
    "        ax1.text(-0.03, (y_lower + y_upper) / 2, str(i + 1))\n",
    "        y_lower += len(cluster_silhouette_vals)\n",
    "\n",
    "    # Get the average silhouette score and plot it\n",
    "    avg_score = np.mean(silhouette_vals)\n",
    "    ax1.axvline(avg_score, linestyle='--', linewidth=2, color='green')\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    ax1.set_xlabel('Silhouette coefficient values')\n",
    "    ax1.set_ylabel('Cluster labels')\n",
    "    ax1.set_title('Silhouette plot for the various clusters', y=1.02);\n",
    "    plt.suptitle(f'Silhouette analysis using k = {k}',fontsize=16, fontweight='semibold', y=1.05);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1715728",
   "metadata": {},
   "source": [
    "## KNN Classifier (K Nearest Neighbours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b7c7e",
   "metadata": {},
   "source": [
    "KNN works by finding the distances between a query and all the examples in the data, selecting the specified number examples (K) closest to the query, then votes for the most frequent label (in the case of classification) or averages the labels (in the case of regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ff3635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required packages\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "656edc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing a dataset for Naive Bayes Algorithm\n",
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "#Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2eb84663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "accuracy=  0.7777777777777778\n",
      "2\n",
      "accuracy=  0.6388888888888888\n",
      "3\n",
      "accuracy=  0.6388888888888888\n",
      "4\n",
      "accuracy=  0.6111111111111112\n",
      "5\n",
      "accuracy=  0.6388888888888888\n",
      "6\n",
      "accuracy=  0.5833333333333334\n",
      "7\n",
      "accuracy=  0.6111111111111112\n",
      "8\n",
      "accuracy=  0.5833333333333334\n",
      "9\n",
      "accuracy=  0.6388888888888888\n",
      "10\n",
      "accuracy=  0.6388888888888888\n",
      "11\n",
      "accuracy=  0.6111111111111112\n",
      "12\n",
      "accuracy=  0.6388888888888888\n",
      "13\n",
      "accuracy=  0.6666666666666666\n",
      "14\n",
      "accuracy=  0.6111111111111112\n",
      "15\n",
      "accuracy=  0.6666666666666666\n",
      "16\n",
      "accuracy=  0.6388888888888888\n",
      "17\n",
      "accuracy=  0.6388888888888888\n",
      "18\n",
      "accuracy=  0.6666666666666666\n",
      "19\n",
      "accuracy=  0.6111111111111112\n",
      "20\n",
      "accuracy=  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#Syntax for creating a KNN Classifier model\n",
    "\n",
    "#class sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30,\n",
    "#p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
    "\n",
    "#Link for explanation : https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "#Simple model\n",
    "for i in range(1,21):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(i)\n",
    "    print(\"accuracy= \",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da02da0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"accuracy= \",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52ccadba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  [[1.375e+01 1.730e+00 2.410e+00 1.600e+01 8.900e+01 2.600e+00 2.760e+00\n",
      "  2.900e-01 1.810e+00 5.600e+00 1.150e+00 2.900e+00 1.320e+03]\n",
      " [1.233e+01 1.100e+00 2.280e+00 1.600e+01 1.010e+02 2.050e+00 1.090e+00\n",
      "  6.300e-01 4.100e-01 3.270e+00 1.250e+00 1.670e+00 6.800e+02]\n",
      " [1.437e+01 1.950e+00 2.500e+00 1.680e+01 1.130e+02 3.850e+00 3.490e+00\n",
      "  2.400e-01 2.180e+00 7.800e+00 8.600e-01 3.450e+00 1.480e+03]\n",
      " [1.412e+01 1.480e+00 2.320e+00 1.680e+01 9.500e+01 2.200e+00 2.430e+00\n",
      "  2.600e-01 1.570e+00 5.000e+00 1.170e+00 2.820e+00 1.280e+03]\n",
      " [1.236e+01 3.830e+00 2.380e+00 2.100e+01 8.800e+01 2.300e+00 9.200e-01\n",
      "  5.000e-01 1.040e+00 7.650e+00 5.600e-01 1.580e+00 5.200e+02]\n",
      " [1.264e+01 1.360e+00 2.020e+00 1.680e+01 1.000e+02 2.020e+00 1.410e+00\n",
      "  5.300e-01 6.200e-01 5.750e+00 9.800e-01 1.590e+00 4.500e+02]\n",
      " [1.234e+01 2.450e+00 2.460e+00 2.100e+01 9.800e+01 2.560e+00 2.110e+00\n",
      "  3.400e-01 1.310e+00 2.800e+00 8.000e-01 3.380e+00 4.380e+02]\n",
      " [1.327e+01 4.280e+00 2.260e+00 2.000e+01 1.200e+02 1.590e+00 6.900e-01\n",
      "  4.300e-01 1.350e+00 1.020e+01 5.900e-01 1.560e+00 8.350e+02]\n",
      " [1.146e+01 3.740e+00 1.820e+00 1.950e+01 1.070e+02 3.180e+00 2.580e+00\n",
      "  2.400e-01 3.580e+00 2.900e+00 7.500e-01 2.810e+00 5.620e+02]\n",
      " [1.164e+01 2.060e+00 2.460e+00 2.160e+01 8.400e+01 1.950e+00 1.690e+00\n",
      "  4.800e-01 1.350e+00 2.800e+00 1.000e+00 2.750e+00 6.800e+02]\n",
      " [1.270e+01 3.870e+00 2.400e+00 2.300e+01 1.010e+02 2.830e+00 2.550e+00\n",
      "  4.300e-01 1.950e+00 2.570e+00 1.190e+00 3.130e+00 4.630e+02]\n",
      " [1.367e+01 1.250e+00 1.920e+00 1.800e+01 9.400e+01 2.100e+00 1.790e+00\n",
      "  3.200e-01 7.300e-01 3.800e+00 1.230e+00 2.460e+00 6.300e+02]\n",
      " [1.293e+01 2.810e+00 2.700e+00 2.100e+01 9.600e+01 1.540e+00 5.000e-01\n",
      "  5.300e-01 7.500e-01 4.600e+00 7.700e-01 2.310e+00 6.000e+02]\n",
      " [1.402e+01 1.680e+00 2.210e+00 1.600e+01 9.600e+01 2.650e+00 2.330e+00\n",
      "  2.600e-01 1.980e+00 4.700e+00 1.040e+00 3.590e+00 1.035e+03]\n",
      " [1.438e+01 3.590e+00 2.280e+00 1.600e+01 1.020e+02 3.250e+00 3.170e+00\n",
      "  2.700e-01 2.190e+00 4.900e+00 1.040e+00 3.440e+00 1.065e+03]\n",
      " [1.420e+01 1.760e+00 2.450e+00 1.520e+01 1.120e+02 3.270e+00 3.390e+00\n",
      "  3.400e-01 1.970e+00 6.750e+00 1.050e+00 2.850e+00 1.450e+03]\n",
      " [1.316e+01 3.570e+00 2.150e+00 2.100e+01 1.020e+02 1.500e+00 5.500e-01\n",
      "  4.300e-01 1.300e+00 4.000e+00 6.000e-01 1.680e+00 8.300e+02]\n",
      " [1.196e+01 1.090e+00 2.300e+00 2.100e+01 1.010e+02 3.380e+00 2.140e+00\n",
      "  1.300e-01 1.650e+00 3.210e+00 9.900e-01 3.130e+00 8.860e+02]\n",
      " [1.350e+01 1.810e+00 2.610e+00 2.000e+01 9.600e+01 2.530e+00 2.610e+00\n",
      "  2.800e-01 1.660e+00 3.520e+00 1.120e+00 3.820e+00 8.450e+02]\n",
      " [1.422e+01 1.700e+00 2.300e+00 1.630e+01 1.180e+02 3.200e+00 3.000e+00\n",
      "  2.600e-01 2.030e+00 6.380e+00 9.400e-01 3.310e+00 9.700e+02]\n",
      " [1.371e+01 5.650e+00 2.450e+00 2.050e+01 9.500e+01 1.680e+00 6.100e-01\n",
      "  5.200e-01 1.060e+00 7.700e+00 6.400e-01 1.740e+00 7.400e+02]\n",
      " [1.184e+01 8.900e-01 2.580e+00 1.800e+01 9.400e+01 2.200e+00 2.210e+00\n",
      "  2.200e-01 2.350e+00 3.050e+00 7.900e-01 3.080e+00 5.200e+02]\n",
      " [1.182e+01 1.720e+00 1.880e+00 1.950e+01 8.600e+01 2.500e+00 1.640e+00\n",
      "  3.700e-01 1.420e+00 2.060e+00 9.400e-01 2.440e+00 4.150e+02]\n",
      " [1.237e+01 1.070e+00 2.100e+00 1.850e+01 8.800e+01 3.520e+00 3.750e+00\n",
      "  2.400e-01 1.950e+00 4.500e+00 1.040e+00 2.770e+00 6.600e+02]\n",
      " [1.285e+01 1.600e+00 2.520e+00 1.780e+01 9.500e+01 2.480e+00 2.370e+00\n",
      "  2.600e-01 1.460e+00 3.930e+00 1.090e+00 3.630e+00 1.015e+03]\n",
      " [1.324e+01 2.590e+00 2.870e+00 2.100e+01 1.180e+02 2.800e+00 2.690e+00\n",
      "  3.900e-01 1.820e+00 4.320e+00 1.040e+00 2.930e+00 7.350e+02]\n",
      " [1.305e+01 1.730e+00 2.040e+00 1.240e+01 9.200e+01 2.720e+00 3.270e+00\n",
      "  1.700e-01 2.910e+00 7.200e+00 1.120e+00 2.910e+00 1.150e+03]\n",
      " [1.383e+01 1.650e+00 2.600e+00 1.720e+01 9.400e+01 2.450e+00 2.990e+00\n",
      "  2.200e-01 2.290e+00 5.600e+00 1.240e+00 3.370e+00 1.265e+03]\n",
      " [1.251e+01 1.240e+00 2.250e+00 1.750e+01 8.500e+01 2.000e+00 5.800e-01\n",
      "  6.000e-01 1.250e+00 5.450e+00 7.500e-01 1.510e+00 6.500e+02]\n",
      " [1.358e+01 1.660e+00 2.360e+00 1.910e+01 1.060e+02 2.860e+00 3.190e+00\n",
      "  2.200e-01 1.950e+00 6.900e+00 1.090e+00 2.880e+00 1.515e+03]\n",
      " [1.378e+01 2.760e+00 2.300e+00 2.200e+01 9.000e+01 1.350e+00 6.800e-01\n",
      "  4.100e-01 1.030e+00 9.580e+00 7.000e-01 1.680e+00 6.150e+02]\n",
      " [1.165e+01 1.670e+00 2.620e+00 2.600e+01 8.800e+01 1.920e+00 1.610e+00\n",
      "  4.000e-01 1.340e+00 2.600e+00 1.360e+00 3.210e+00 5.620e+02]\n",
      " [1.245e+01 3.030e+00 2.640e+00 2.700e+01 9.700e+01 1.900e+00 5.800e-01\n",
      "  6.300e-01 1.140e+00 7.500e+00 6.700e-01 1.730e+00 8.800e+02]\n",
      " [1.260e+01 2.460e+00 2.200e+00 1.850e+01 9.400e+01 1.620e+00 6.600e-01\n",
      "  6.300e-01 9.400e-01 7.100e+00 7.300e-01 1.580e+00 6.950e+02]\n",
      " [1.377e+01 1.900e+00 2.680e+00 1.710e+01 1.150e+02 3.000e+00 2.790e+00\n",
      "  3.900e-01 1.680e+00 6.300e+00 1.130e+00 2.930e+00 1.375e+03]\n",
      " [1.358e+01 2.580e+00 2.690e+00 2.450e+01 1.050e+02 1.550e+00 8.400e-01\n",
      "  3.900e-01 1.540e+00 8.660e+00 7.400e-01 1.800e+00 7.500e+02]]\n",
      "Expected output :  [0 1 0 0 2 1 1 2 1 1 1 1 2 0 0 0 2 1 0 0 2 1 1 1 0 0 0 0 2 0 2 1 2 2 0 2]\n",
      "Predicted output :  [0 2 0 0 1 1 1 0 2 2 1 2 2 0 0 0 0 0 0 0 2 1 1 2 0 1 0 0 2 0 2 2 0 2 0 2]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the input & output\n",
    "\n",
    "# Input: A two-dimensional array which contains all the features of the wine dataset\n",
    "print(\"Input : \", X_test)\n",
    "\n",
    "# Output: The ouput array is the prediction\n",
    "print(\"Expected output : \", y_test)\n",
    "print(\"Predicted output : \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aaf584ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score: 0.6666666666666666\n",
      "Mean Squared Error: 0.5833333333333334\n",
      "Root Mean Squared Error: 0.7637626158259734\n",
      "R^2 value: 0.10849056603773588\n",
      "Precision: 0.6743697478991596\n",
      "Recall: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Accuracy\n",
    "# Importing necessary packages\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Accuracy\n",
    "print(\"Test Accuracy Score:\", knn.score(X_test, y_test)) #Predicted correctly/Total values\n",
    "\n",
    "# Mean Squared Error\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))# tells you how close a regression line is to a set of points\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(\"Root Mean Squared Error:\", mean_squared_error(y_test, y_pred, squared=False)) \n",
    "\n",
    "# R2 Score\n",
    "print(\"R^2 value:\", r2_score(y_test,y_pred)) # correlation between actual and predicted value\n",
    "\n",
    "# Precision\n",
    "print(\"Precision:\",precision_score(y_test, y_pred, average='weighted')) #Proportion of positive identifications actually correct\n",
    "\n",
    "# Recall\n",
    "print(\"Recall:\",recall_score(y_test, y_pred, average='weighted')) # Proportion of actual positives was identified correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9235e35a",
   "metadata": {},
   "source": [
    "## Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aae5d1",
   "metadata": {},
   "source": [
    "Support vector machines (SVMs) are powerful yet flexible supervised machine learning methods used for classification, regression, and, outliers' detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ea7209",
   "metadata": {},
   "source": [
    "SVC fits the data provided, returning a \"best fit\" hyperplane that divides, or categorizes the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ad4b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required packages\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e8f0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing a dataset for Support Vector Classifier Algorithm\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "#Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "414b1f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax for creating a Support Vector Classifier model:\n",
    "\n",
    "\n",
    "# SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, \n",
    "# cache_size=200, class_weight=None, verbose=False, max_iter=- 1, decision_function_shape='ovr', break_ties=False,\n",
    "# random_state=None)\n",
    "\n",
    "# Link for explanation of terms : https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "# A simple model:\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a1128b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  [[1.522e+01 3.062e+01 1.034e+02 ... 2.356e-01 4.089e-01 1.409e-01]\n",
      " [1.283e+01 2.233e+01 8.526e+01 ... 1.977e-01 3.407e-01 1.243e-01]\n",
      " [1.791e+01 2.102e+01 1.244e+02 ... 1.964e-01 3.245e-01 1.198e-01]\n",
      " ...\n",
      " [1.080e+01 2.198e+01 6.879e+01 ... 7.485e-02 2.965e-01 7.662e-02]\n",
      " [9.465e+00 2.101e+01 6.011e+01 ... 6.517e-02 2.878e-01 9.211e-02]\n",
      " [2.026e+01 2.303e+01 1.324e+02 ... 1.573e-01 3.689e-01 8.368e-02]]\n",
      "Expected output :  [0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1\n",
      " 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 0 1 0\n",
      " 1 1 0]\n",
      "Predicted output :  [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1\n",
      " 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0\n",
      " 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the input & output\n",
    "\n",
    "# Input: A two-dimensional array which contains all the features of the breast cancer dataset\n",
    "print(\"Input : \", X_test)\n",
    "\n",
    "# Output: The ouput array is the prediction\n",
    "print(\"Expected output : \", y_test)\n",
    "print(\"Predicted output : \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32997078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score: 0.868421052631579\n",
      "Mean Squared Error: 0.13157894736842105\n",
      "Root Mean Squared Error: 0.3627381250550058\n",
      "R^2 value: 0.44480519480519487\n",
      "Precision: 0.8839773354879621\n",
      "Recall: 0.868421052631579\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Accuracy\n",
    "# Importing necessary packages\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Accuracy\n",
    "print(\"Test Accuracy Score:\", svc.score(X_test, y_test)) #Predicted correctly/Total values\n",
    "\n",
    "# Mean Squared Error\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))# tells you how close a regression line is to a set of points\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(\"Root Mean Squared Error:\", mean_squared_error(y_test, y_pred, squared=False)) \n",
    "\n",
    "# R2 Score\n",
    "print(\"R^2 value:\", r2_score(y_test,y_pred)) # correlation between actual and predicted value\n",
    "\n",
    "# Precision\n",
    "print(\"Precision:\",precision_score(y_test, y_pred, average='weighted')) #Proportion of positive identifications actually correct\n",
    "\n",
    "# Recall\n",
    "print(\"Recall:\",recall_score(y_test, y_pred, average='weighted')) # Proportion of actual positives was identified correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528985ac",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10981ddb",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is an unsupervised machine learning algorithm which can be used as a linear dimensionality reduction technique that can be utilized for extracting information from a high-dimensional space by projecting it into a lower-dimensional sub-space.\n",
    "\n",
    "PCA can't be used for prediction itself but can be used to reduce the dimensions in the training data to fit in for some algorithms such as KMeans etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9381cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required packages\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "215e3e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing a dataset for Principal Component Analysis\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "#Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa9bc6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db680f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.68412563,  0.31939725],\n",
       "       [-2.71414169, -0.17700123],\n",
       "       [-2.88899057, -0.14494943],\n",
       "       [-2.74534286, -0.31829898],\n",
       "       [-2.72871654,  0.32675451],\n",
       "       [-2.28085963,  0.74133045],\n",
       "       [-2.82053775, -0.08946138],\n",
       "       [-2.62614497,  0.16338496],\n",
       "       [-2.88638273, -0.57831175],\n",
       "       [-2.6727558 , -0.11377425],\n",
       "       [-2.50694709,  0.6450689 ],\n",
       "       [-2.61275523,  0.01472994],\n",
       "       [-2.78610927, -0.235112  ],\n",
       "       [-3.22380374, -0.51139459],\n",
       "       [-2.64475039,  1.17876464],\n",
       "       [-2.38603903,  1.33806233],\n",
       "       [-2.62352788,  0.81067951],\n",
       "       [-2.64829671,  0.31184914],\n",
       "       [-2.19982032,  0.87283904],\n",
       "       [-2.5879864 ,  0.51356031],\n",
       "       [-2.31025622,  0.39134594],\n",
       "       [-2.54370523,  0.43299606],\n",
       "       [-3.21593942,  0.13346807],\n",
       "       [-2.30273318,  0.09870885],\n",
       "       [-2.35575405, -0.03728186],\n",
       "       [-2.50666891, -0.14601688],\n",
       "       [-2.46882007,  0.13095149],\n",
       "       [-2.56231991,  0.36771886],\n",
       "       [-2.63953472,  0.31203998],\n",
       "       [-2.63198939, -0.19696122],\n",
       "       [-2.58739848, -0.20431849],\n",
       "       [-2.4099325 ,  0.41092426],\n",
       "       [-2.64886233,  0.81336382],\n",
       "       [-2.59873675,  1.09314576],\n",
       "       [-2.63692688, -0.12132235],\n",
       "       [-2.86624165,  0.06936447],\n",
       "       [-2.62523805,  0.59937002],\n",
       "       [-2.80068412,  0.26864374],\n",
       "       [-2.98050204, -0.48795834],\n",
       "       [-2.59000631,  0.22904384],\n",
       "       [-2.77010243,  0.26352753],\n",
       "       [-2.84936871, -0.94096057],\n",
       "       [-2.99740655, -0.34192606],\n",
       "       [-2.40561449,  0.18887143],\n",
       "       [-2.20948924,  0.43666314],\n",
       "       [-2.71445143, -0.2502082 ],\n",
       "       [-2.53814826,  0.50377114],\n",
       "       [-2.83946217, -0.22794557],\n",
       "       [-2.54308575,  0.57941002],\n",
       "       [-2.70335978,  0.10770608],\n",
       "       [ 1.28482569,  0.68516047],\n",
       "       [ 0.93248853,  0.31833364],\n",
       "       [ 1.46430232,  0.50426282],\n",
       "       [ 0.18331772, -0.82795901],\n",
       "       [ 1.08810326,  0.07459068],\n",
       "       [ 0.64166908, -0.41824687],\n",
       "       [ 1.09506066,  0.28346827],\n",
       "       [-0.74912267, -1.00489096],\n",
       "       [ 1.04413183,  0.2283619 ],\n",
       "       [-0.0087454 , -0.72308191],\n",
       "       [-0.50784088, -1.26597119],\n",
       "       [ 0.51169856, -0.10398124],\n",
       "       [ 0.26497651, -0.55003646],\n",
       "       [ 0.98493451, -0.12481785],\n",
       "       [-0.17392537, -0.25485421],\n",
       "       [ 0.92786078,  0.46717949],\n",
       "       [ 0.66028376, -0.35296967],\n",
       "       [ 0.23610499, -0.33361077],\n",
       "       [ 0.94473373, -0.54314555],\n",
       "       [ 0.04522698, -0.58383438],\n",
       "       [ 1.11628318, -0.08461685],\n",
       "       [ 0.35788842, -0.06892503],\n",
       "       [ 1.29818388, -0.32778731],\n",
       "       [ 0.92172892, -0.18273779],\n",
       "       [ 0.71485333,  0.14905594],\n",
       "       [ 0.90017437,  0.32850447],\n",
       "       [ 1.33202444,  0.24444088],\n",
       "       [ 1.55780216,  0.26749545],\n",
       "       [ 0.81329065, -0.1633503 ],\n",
       "       [-0.30558378, -0.36826219],\n",
       "       [-0.06812649, -0.70517213],\n",
       "       [-0.18962247, -0.68028676],\n",
       "       [ 0.13642871, -0.31403244],\n",
       "       [ 1.38002644, -0.42095429],\n",
       "       [ 0.58800644, -0.48428742],\n",
       "       [ 0.80685831,  0.19418231],\n",
       "       [ 1.22069088,  0.40761959],\n",
       "       [ 0.81509524, -0.37203706],\n",
       "       [ 0.24595768, -0.2685244 ],\n",
       "       [ 0.16641322, -0.68192672],\n",
       "       [ 0.46480029, -0.67071154],\n",
       "       [ 0.8908152 , -0.03446444],\n",
       "       [ 0.23054802, -0.40438585],\n",
       "       [-0.70453176, -1.01224823],\n",
       "       [ 0.35698149, -0.50491009],\n",
       "       [ 0.33193448, -0.21265468],\n",
       "       [ 0.37621565, -0.29321893],\n",
       "       [ 0.64257601,  0.01773819],\n",
       "       [-0.90646986, -0.75609337],\n",
       "       [ 0.29900084, -0.34889781],\n",
       "       [ 2.53119273, -0.00984911],\n",
       "       [ 1.41523588, -0.57491635],\n",
       "       [ 2.61667602,  0.34390315],\n",
       "       [ 1.97153105, -0.1797279 ],\n",
       "       [ 2.35000592, -0.04026095],\n",
       "       [ 3.39703874,  0.55083667],\n",
       "       [ 0.52123224, -1.19275873],\n",
       "       [ 2.93258707,  0.3555    ],\n",
       "       [ 2.32122882, -0.2438315 ],\n",
       "       [ 2.91675097,  0.78279195],\n",
       "       [ 1.66177415,  0.24222841],\n",
       "       [ 1.80340195, -0.21563762],\n",
       "       [ 2.1655918 ,  0.21627559],\n",
       "       [ 1.34616358, -0.77681835],\n",
       "       [ 1.58592822, -0.53964071],\n",
       "       [ 1.90445637,  0.11925069],\n",
       "       [ 1.94968906,  0.04194326],\n",
       "       [ 3.48705536,  1.17573933],\n",
       "       [ 3.79564542,  0.25732297],\n",
       "       [ 1.30079171, -0.76114964],\n",
       "       [ 2.42781791,  0.37819601],\n",
       "       [ 1.19900111, -0.60609153],\n",
       "       [ 3.49992004,  0.4606741 ],\n",
       "       [ 1.38876613, -0.20439933],\n",
       "       [ 2.2754305 ,  0.33499061],\n",
       "       [ 2.61409047,  0.56090136],\n",
       "       [ 1.25850816, -0.17970479],\n",
       "       [ 1.29113206, -0.11666865],\n",
       "       [ 2.12360872, -0.20972948],\n",
       "       [ 2.38800302,  0.4646398 ],\n",
       "       [ 2.84167278,  0.37526917],\n",
       "       [ 3.23067366,  1.37416509],\n",
       "       [ 2.15943764, -0.21727758],\n",
       "       [ 1.44416124, -0.14341341],\n",
       "       [ 1.78129481, -0.49990168],\n",
       "       [ 3.07649993,  0.68808568],\n",
       "       [ 2.14424331,  0.1400642 ],\n",
       "       [ 1.90509815,  0.04930053],\n",
       "       [ 1.16932634, -0.16499026],\n",
       "       [ 2.10761114,  0.37228787],\n",
       "       [ 2.31415471,  0.18365128],\n",
       "       [ 1.9222678 ,  0.40920347],\n",
       "       [ 1.41523588, -0.57491635],\n",
       "       [ 2.56301338,  0.2778626 ],\n",
       "       [ 2.41874618,  0.3047982 ],\n",
       "       [ 1.94410979,  0.1875323 ],\n",
       "       [ 1.52716661, -0.37531698],\n",
       "       [ 1.76434572,  0.07885885],\n",
       "       [ 1.90094161,  0.11662796],\n",
       "       [ 1.39018886, -0.28266094]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e19d4",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46e61f7",
   "metadata": {},
   "source": [
    "A classifier that contains a number of decision trees on various subsets of the given dataset and takes the average to improve the predictive accuracy of that dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "595f5987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a13332d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing a dataset for Random Forest Classifier Algorithm\n",
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "#Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b564b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax for creating a Random Forest Classifier model:\n",
    "\n",
    "\n",
    "# RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, \n",
    "# min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, \n",
    "# min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, \n",
    "# warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "# Link for explanation of terms : https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "# A simple model:\n",
    "rfm = RandomForestClassifier()\n",
    "rfm.fit(X_train, y_train)\n",
    "y_pred = rfm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac66e26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  [[1.229e+01 2.830e+00 2.220e+00 1.800e+01 8.800e+01 2.450e+00 2.250e+00\n",
      "  2.500e-01 1.990e+00 2.150e+00 1.150e+00 3.300e+00 2.900e+02]\n",
      " [1.293e+01 2.810e+00 2.700e+00 2.100e+01 9.600e+01 1.540e+00 5.000e-01\n",
      "  5.300e-01 7.500e-01 4.600e+00 7.700e-01 2.310e+00 6.000e+02]\n",
      " [1.410e+01 2.020e+00 2.400e+00 1.880e+01 1.030e+02 2.750e+00 2.920e+00\n",
      "  3.200e-01 2.380e+00 6.200e+00 1.070e+00 2.750e+00 1.060e+03]\n",
      " [1.270e+01 3.550e+00 2.360e+00 2.150e+01 1.060e+02 1.700e+00 1.200e+00\n",
      "  1.700e-01 8.400e-01 5.000e+00 7.800e-01 1.290e+00 6.000e+02]\n",
      " [1.416e+01 2.510e+00 2.480e+00 2.000e+01 9.100e+01 1.680e+00 7.000e-01\n",
      "  4.400e-01 1.240e+00 9.700e+00 6.200e-01 1.710e+00 6.600e+02]\n",
      " [1.146e+01 3.740e+00 1.820e+00 1.950e+01 1.070e+02 3.180e+00 2.580e+00\n",
      "  2.400e-01 3.580e+00 2.900e+00 7.500e-01 2.810e+00 5.620e+02]\n",
      " [1.176e+01 2.680e+00 2.920e+00 2.000e+01 1.030e+02 1.750e+00 2.030e+00\n",
      "  6.000e-01 1.050e+00 3.800e+00 1.230e+00 2.500e+00 6.070e+02]\n",
      " [1.184e+01 8.900e-01 2.580e+00 1.800e+01 9.400e+01 2.200e+00 2.210e+00\n",
      "  2.200e-01 2.350e+00 3.050e+00 7.900e-01 3.080e+00 5.200e+02]\n",
      " [1.410e+01 2.160e+00 2.300e+00 1.800e+01 1.050e+02 2.950e+00 3.320e+00\n",
      "  2.200e-01 2.380e+00 5.750e+00 1.250e+00 3.170e+00 1.510e+03]\n",
      " [1.345e+01 3.700e+00 2.600e+00 2.300e+01 1.110e+02 1.700e+00 9.200e-01\n",
      "  4.300e-01 1.460e+00 1.068e+01 8.500e-01 1.560e+00 6.950e+02]\n",
      " [1.438e+01 1.870e+00 2.380e+00 1.200e+01 1.020e+02 3.300e+00 3.640e+00\n",
      "  2.900e-01 2.960e+00 7.500e+00 1.200e+00 3.000e+00 1.547e+03]\n",
      " [1.305e+01 5.800e+00 2.130e+00 2.150e+01 8.600e+01 2.620e+00 2.650e+00\n",
      "  3.000e-01 2.010e+00 2.600e+00 7.300e-01 3.100e+00 3.800e+02]\n",
      " [1.237e+01 1.630e+00 2.300e+00 2.450e+01 8.800e+01 2.220e+00 2.450e+00\n",
      "  4.000e-01 1.900e+00 2.120e+00 8.900e-01 2.780e+00 3.420e+02]\n",
      " [1.341e+01 3.840e+00 2.120e+00 1.880e+01 9.000e+01 2.450e+00 2.680e+00\n",
      "  2.700e-01 1.480e+00 4.280e+00 9.100e-01 3.000e+00 1.035e+03]\n",
      " [1.390e+01 1.680e+00 2.120e+00 1.600e+01 1.010e+02 3.100e+00 3.390e+00\n",
      "  2.100e-01 2.140e+00 6.100e+00 9.100e-01 3.330e+00 9.850e+02]\n",
      " [1.287e+01 4.610e+00 2.480e+00 2.150e+01 8.600e+01 1.700e+00 6.500e-01\n",
      "  4.700e-01 8.600e-01 7.650e+00 5.400e-01 1.860e+00 6.250e+02]\n",
      " [1.316e+01 2.360e+00 2.670e+00 1.860e+01 1.010e+02 2.800e+00 3.240e+00\n",
      "  3.000e-01 2.810e+00 5.680e+00 1.030e+00 3.170e+00 1.185e+03]\n",
      " [1.372e+01 1.430e+00 2.500e+00 1.670e+01 1.080e+02 3.400e+00 3.670e+00\n",
      "  1.900e-01 2.040e+00 6.800e+00 8.900e-01 2.870e+00 1.285e+03]\n",
      " [1.243e+01 1.530e+00 2.290e+00 2.150e+01 8.600e+01 2.740e+00 3.150e+00\n",
      "  3.900e-01 1.770e+00 3.940e+00 6.900e-01 2.840e+00 3.520e+02]\n",
      " [1.384e+01 4.120e+00 2.380e+00 1.950e+01 8.900e+01 1.800e+00 8.300e-01\n",
      "  4.800e-01 1.560e+00 9.010e+00 5.700e-01 1.640e+00 4.800e+02]\n",
      " [1.184e+01 2.890e+00 2.230e+00 1.800e+01 1.120e+02 1.720e+00 1.320e+00\n",
      "  4.300e-01 9.500e-01 2.650e+00 9.600e-01 2.520e+00 5.000e+02]\n",
      " [1.196e+01 1.090e+00 2.300e+00 2.100e+01 1.010e+02 3.380e+00 2.140e+00\n",
      "  1.300e-01 1.650e+00 3.210e+00 9.900e-01 3.130e+00 8.860e+02]\n",
      " [1.237e+01 1.130e+00 2.160e+00 1.900e+01 8.700e+01 3.500e+00 3.100e+00\n",
      "  1.900e-01 1.870e+00 4.450e+00 1.220e+00 2.870e+00 4.200e+02]\n",
      " [1.339e+01 1.770e+00 2.620e+00 1.610e+01 9.300e+01 2.850e+00 2.940e+00\n",
      "  3.400e-01 1.450e+00 4.800e+00 9.200e-01 3.220e+00 1.195e+03]\n",
      " [1.329e+01 1.970e+00 2.680e+00 1.680e+01 1.020e+02 3.000e+00 3.230e+00\n",
      "  3.100e-01 1.660e+00 6.000e+00 1.070e+00 2.840e+00 1.270e+03]\n",
      " [1.208e+01 1.130e+00 2.510e+00 2.400e+01 7.800e+01 2.000e+00 1.580e+00\n",
      "  4.000e-01 1.400e+00 2.200e+00 1.310e+00 2.720e+00 6.300e+02]\n",
      " [1.323e+01 3.300e+00 2.280e+00 1.850e+01 9.800e+01 1.800e+00 8.300e-01\n",
      "  6.100e-01 1.870e+00 1.052e+01 5.600e-01 1.510e+00 6.750e+02]\n",
      " [1.305e+01 2.050e+00 3.220e+00 2.500e+01 1.240e+02 2.630e+00 2.680e+00\n",
      "  4.700e-01 1.920e+00 3.580e+00 1.130e+00 3.200e+00 8.300e+02]\n",
      " [1.437e+01 1.950e+00 2.500e+00 1.680e+01 1.130e+02 3.850e+00 3.490e+00\n",
      "  2.400e-01 2.180e+00 7.800e+00 8.600e-01 3.450e+00 1.480e+03]\n",
      " [1.376e+01 1.530e+00 2.700e+00 1.950e+01 1.320e+02 2.950e+00 2.740e+00\n",
      "  5.000e-01 1.350e+00 5.400e+00 1.250e+00 3.000e+00 1.235e+03]\n",
      " [1.237e+01 9.400e-01 1.360e+00 1.060e+01 8.800e+01 1.980e+00 5.700e-01\n",
      "  2.800e-01 4.200e-01 1.950e+00 1.050e+00 1.820e+00 5.200e+02]\n",
      " [1.208e+01 1.390e+00 2.500e+00 2.250e+01 8.400e+01 2.560e+00 2.290e+00\n",
      "  4.300e-01 1.040e+00 2.900e+00 9.300e-01 3.190e+00 3.850e+02]\n",
      " [1.422e+01 3.990e+00 2.510e+00 1.320e+01 1.280e+02 3.000e+00 3.040e+00\n",
      "  2.000e-01 2.080e+00 5.100e+00 8.900e-01 3.530e+00 7.600e+02]\n",
      " [1.311e+01 1.900e+00 2.750e+00 2.550e+01 1.160e+02 2.200e+00 1.280e+00\n",
      "  2.600e-01 1.560e+00 7.100e+00 6.100e-01 1.330e+00 4.250e+02]\n",
      " [1.332e+01 3.240e+00 2.380e+00 2.150e+01 9.200e+01 1.930e+00 7.600e-01\n",
      "  4.500e-01 1.250e+00 8.420e+00 5.500e-01 1.620e+00 6.500e+02]\n",
      " [1.349e+01 3.590e+00 2.190e+00 1.950e+01 8.800e+01 1.620e+00 4.800e-01\n",
      "  5.800e-01 8.800e-01 5.700e+00 8.100e-01 1.820e+00 5.800e+02]]\n",
      "Expected output :  [1 2 0 2 2 1 1 1 0 2 0 1 1 0 0 2 0 0 1 2 1 1 1 0 0 1 2 0 0 0 1 1 0 2 2 2]\n",
      "Predicted output :  [1 2 0 2 2 1 1 1 0 2 0 1 1 0 0 2 0 0 1 2 1 1 1 0 0 1 2 0 0 0 1 1 0 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the input & output\n",
    "\n",
    "# Input: A two-dimensional array which contains all the features of the breast cancer dataset\n",
    "print(\"Input : \", X_test)\n",
    "\n",
    "# Output: The ouput array is the prediction\n",
    "print(\"Expected output : \", y_test)\n",
    "print(\"Predicted output : \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3676f3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score: 1.0\n",
      "Mean Squared Error: 0.0\n",
      "Root Mean Squared Error: 0.0\n",
      "R^2 value: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Accuracy\n",
    "# Importing necessary packages\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Accuracy\n",
    "print(\"Test Accuracy Score:\", rfm.score(X_test, y_test)) #Predicted correctly/Total values\n",
    "\n",
    "# Mean Squared Error\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))# tells you how close a regression line is to a set of points\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(\"Root Mean Squared Error:\", mean_squared_error(y_test, y_pred, squared=False)) \n",
    "\n",
    "# R2 Score\n",
    "print(\"R^2 value:\", r2_score(y_test,y_pred)) # correlation between actual and predicted value\n",
    "\n",
    "# Precision\n",
    "print(\"Precision:\",precision_score(y_test, y_pred, average='weighted')) #Proportion of positive identifications actually correct\n",
    "\n",
    "# Recall\n",
    "print(\"Recall:\",recall_score(y_test, y_pred, average='weighted')) # Proportion of actual positives was identified correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6607af6",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c1a0a0",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier Algorithm gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa003985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required packages\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "81147e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing a dataset for Random Forest Classifier Algorithm\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "#Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01becd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Syntax for creating a Gradient Boosting Classifier model:\n",
    "\n",
    "\n",
    "# GradientBoostingClassifier(*, loss='log_loss', learning_rate=0.1, n_estimators=100, subsample=1.0, \n",
    "# criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3,\n",
    "# min_impurity_decrease=0.0, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None,\n",
    "# warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "\n",
    "# Link for explanation of terms : https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "\n",
    "# A simple model:\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train, y_train)\n",
    "y_pred = gbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10658900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  [[1.678e+01 1.880e+01 1.093e+02 ... 1.474e-01 2.810e-01 7.228e-02]\n",
      " [1.174e+01 1.469e+01 7.631e+01 ... 1.056e-01 2.604e-01 9.879e-02]\n",
      " [9.777e+00 1.699e+01 6.250e+01 ... 5.334e-02 2.533e-01 8.468e-02]\n",
      " ...\n",
      " [1.865e+01 1.760e+01 1.237e+02 ... 2.378e-01 3.799e-01 9.185e-02]\n",
      " [1.272e+01 1.767e+01 8.098e+01 ... 3.612e-02 2.165e-01 6.025e-02]\n",
      " [1.396e+01 1.705e+01 9.143e+01 ... 1.374e-01 3.068e-01 7.957e-02]]\n",
      "Expected output :  [0 1 1 0 1 0 0 1 1 0 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 1\n",
      " 1 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 0 0 0\n",
      " 0 1 0]\n",
      "Predicted output :  [0 1 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1\n",
      " 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1\n",
      " 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 0 0 0\n",
      " 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the input & output\n",
    "\n",
    "# Input: A two-dimensional array which contains all the features of the diabetes dataset\n",
    "print(\"Input : \", X_test)\n",
    "\n",
    "# Output: The ouput array is the prediction\n",
    "print(\"Expected output : \", y_test)\n",
    "print(\"Predicted output : \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e1ad49b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score: 0.9298245614035088\n",
      "Mean Squared Error: 0.07017543859649122\n",
      "Root Mean Squared Error: 0.26490647141300877\n",
      "R^2 value: 0.713657770800628\n",
      "Precision: 0.9337896001057343\n",
      "Recall: 0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Accuracy\n",
    "# Importing necessary packages\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Accuracy\n",
    "print(\"Test Accuracy Score:\", gbc.score(X_test, y_test)) #Predicted correctly/Total values\n",
    "\n",
    "# Mean Squared Error\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))# tells you how close a regression line is to a set of points\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(\"Root Mean Squared Error:\", mean_squared_error(y_test, y_pred, squared=False)) \n",
    "\n",
    "# R2 Score\n",
    "print(\"R^2 value:\", r2_score(y_test,y_pred)) # correlation between actual and predicted value\n",
    "\n",
    "# Precision\n",
    "print(\"Precision:\",precision_score(y_test, y_pred, average='weighted')) #Proportion of positive identifications actually correct\n",
    "\n",
    "# Recall\n",
    "print(\"Recall:\",recall_score(y_test, y_pred, average='weighted')) # Proportion of actual positives was identified correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6f703a",
   "metadata": {},
   "source": [
    "## Ada Boost Classifier Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec49c73",
   "metadata": {},
   "source": [
    "An AdaBoost classifier is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0601afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "337e0396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataset using make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=4,n_informative=2, n_redundant=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b96ee610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax for creating a Ada Boost Classifier model:\n",
    "\n",
    "\n",
    "# AdaBoostClassifier(base_estimator=None, *, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', \n",
    "# random_state=None)\n",
    "\n",
    "# Link for explanation of terms : https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "\n",
    "# A simple model:\n",
    "abc = AdaBoostClassifier(n_estimators=100)\n",
    "abc.fit(X, y)\n",
    "y_pred = abc.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5dc95855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  [[ 0.41990896  0.34525805 -1.07787865 -0.59612762]\n",
      " [ 0.82011282  2.09912064 -0.78509653  0.56525794]\n",
      " [-0.08010784  0.84640954  0.83451817 -0.24263468]\n",
      " ...\n",
      " [ 1.06817597 -1.58787764 -1.05677263 -1.09622545]\n",
      " [ 1.37551917  0.54300574 -1.26216334  0.60531574]\n",
      " [ 1.83671262  0.50537454 -1.71631807 -0.07256818]]\n",
      "Expected output :  [0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1\n",
      " 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0\n",
      " 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 1 0 1 0 0 0\n",
      " 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1\n",
      " 1 0 1 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1\n",
      " 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 1 1 0 0 1\n",
      " 0 1 0 1 1 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1\n",
      " 1 0 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0\n",
      " 1 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 1 0 1 1\n",
      " 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1\n",
      " 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1\n",
      " 1 0 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 1 0\n",
      " 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1\n",
      " 1 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1\n",
      " 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 1\n",
      " 1 0 1 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0 0 1 0\n",
      " 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 1 0\n",
      " 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 0 0\n",
      " 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1\n",
      " 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 0 1 1 1\n",
      " 1]\n",
      "Predicted output :  [1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1\n",
      " 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0\n",
      " 0 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 0 1 0 0 0\n",
      " 1 0 0 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1\n",
      " 1 0 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1\n",
      " 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1\n",
      " 0 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 1 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1\n",
      " 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0\n",
      " 1 1 1 0 0 0 1 0 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 0 1\n",
      " 0 1 1 0 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1\n",
      " 0 1 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1\n",
      " 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1\n",
      " 1 0 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0\n",
      " 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1\n",
      " 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1\n",
      " 0 1 1 0 1 1 1 0 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 1\n",
      " 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 1 0\n",
      " 1 1 0 0 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 0 0\n",
      " 0 1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1\n",
      " 1 0 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 1\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the input & output\n",
    "\n",
    "# Input: A two-dimensional array which contains all the features of the diabetes dataset\n",
    "print(\"Input : \", X)\n",
    "\n",
    "# Output: The ouput array is the prediction\n",
    "print(\"Expected output : \", y)\n",
    "print(\"Predicted output : \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5ebdf893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score: 0.946\n",
      "Mean Squared Error: 0.054\n",
      "Root Mean Squared Error: 0.232379000772445\n",
      "R^2 value: 0.7839991359965439\n",
      "Precision: 0.9460067042413527\n",
      "Recall: 0.946\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Accuracy\n",
    "# Importing necessary packages\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Accuracy\n",
    "print(\"Test Accuracy Score:\", abc.score(X, y)) #Predicted correctly/Total values\n",
    "\n",
    "# Mean Squared Error\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y, y_pred))# tells you how close a regression line is to a set of points\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(\"Root Mean Squared Error:\", mean_squared_error(y, y_pred, squared=False)) \n",
    "\n",
    "# R2 Score\n",
    "print(\"R^2 value:\", r2_score(y,y_pred)) # correlation between actual and predicted value\n",
    "\n",
    "# Precision\n",
    "print(\"Precision:\",precision_score(y, y_pred, average='weighted')) #Proportion of positive identifications actually correct\n",
    "\n",
    "# Recall\n",
    "print(\"Recall:\",recall_score(y, y_pred, average='weighted')) # Proportion of actual positives was identified correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b641e49",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94596501",
   "metadata": {},
   "source": [
    "Gradient Boosting Regressor builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. \n",
    "In each stage a regression tree is fit on the negative gradient of the given loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2995f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cfa0b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset using make_regression \n",
    "X, y = make_regression(n_samples=200, n_features=20, n_informative=10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1d243f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax for creating a Gradient Boosting Regressor model:\n",
    "\n",
    "\n",
    "# GradientBoostingRegressor(*, loss='squared_error', learning_rate=0.1, n_estimators=100, subsample=1.0, \n",
    "# criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, \n",
    "# min_impurity_decrease=0.0, init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, \n",
    "# max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001,\n",
    "# ccp_alpha=0.0)\n",
    "\n",
    "# Link for explanation of terms : https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "\n",
    "# A simple model:\n",
    "gbr = GradientBoostingRegressor(n_estimators=200)\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred = gbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2066ba1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  [[ 0.06276158  0.14775339  1.21483326 ...  0.10942871  0.32972158\n",
      "   1.07057624]\n",
      " [ 0.93074863 -1.97625845 -0.9051198  ...  1.68468215 -1.0957102\n",
      "   0.97331611]\n",
      " [-0.47576483 -0.52124626 -0.90448905 ...  0.33483579 -0.06281934\n",
      "   0.25034936]\n",
      " ...\n",
      " [-0.17380981 -0.29037964 -0.17171872 ...  0.90995003  0.6106982\n",
      "   0.36895691]\n",
      " [-0.00619485  1.26507622 -1.4976803  ...  0.43405465 -0.20339444\n",
      "   0.10463785]\n",
      " [-1.0908997   1.86900274  0.6214221  ... -0.84778048  1.69789143\n",
      "   0.38784387]]\n",
      "Expected output :  [ 106.51305391  135.89428234  265.1214804   137.4777856   -33.37209571\n",
      " -213.373006     98.94618324  -74.2863943   414.90654344  154.16682422\n",
      " -113.52192868  -19.31707284   25.00695291  236.77992747  136.35133798\n",
      "  418.08807876   79.13066799  263.51955548 -457.09088394  -87.88662318\n",
      "   24.92527483  -51.78961675  -88.31963971 -224.99767148  313.55793735\n",
      "  200.47944567   20.03013573  -55.21118006  483.99957653 -125.8990573\n",
      "   51.76119387 -229.18614581 -192.16988625    7.4819144  -120.65512656\n",
      "  -28.73178128 -248.81837055  196.2339786   249.67765286  112.60359463\n",
      "   50.79067245  -23.44116627 -169.26470591  -53.76107217  162.94480062\n",
      "  -11.24648071  130.04920735 -151.93978314 -156.2034508   -78.52539406\n",
      "  208.77676589 -143.97210361   93.03267624 -266.8673043    45.12242218\n",
      "  201.36738822  -68.27236641 -118.94756071  214.33983893  -26.60076267]\n",
      "Predicted output :  [ -40.17037275   91.72338489  192.04856902  128.95725183  -93.16983353\n",
      "  -59.99900118  181.27006503 -148.38323662  227.38548994  239.87984494\n",
      "   77.85119328  -22.76357865  132.32621514  180.51074254   41.10581112\n",
      "  141.93302184   74.90394305    0.92980895 -333.33975467  -97.9463033\n",
      "   96.7097515   -28.16633667 -140.40208737 -131.37217534  186.78635352\n",
      "  182.66816985 -187.91355471  -33.53916162  321.70213402   82.47316043\n",
      "   32.69875636 -251.96315372 -167.01478293   13.43713405  -55.36272308\n",
      "  -40.41270453 -187.40553603  192.87184931  142.51956565  177.33978867\n",
      "  182.92872867  140.42371923 -151.94383754  -89.98472508   80.98352543\n",
      " -143.67847496  136.78189818 -169.89966114 -262.2528055   -29.06303361\n",
      "  231.0760413  -104.01895292  131.6060658  -192.49577471   34.57751278\n",
      "  141.983216    -33.62861061  -17.6728487   141.85169623   28.44215153]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the input & output\n",
    "\n",
    "# Input: A two-dimensional array which contains all the features of the diabetes dataset\n",
    "print(\"Input : \", X_test)\n",
    "\n",
    "# Output: The ouput array is the prediction\n",
    "print(\"Expected output : \", y_test)\n",
    "print(\"Predicted output : \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b3e937b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 10349.708921230418\n",
      "Root Mean Squared Error: 101.7335191627146\n",
      "R^2 Score: 0.6911396453893272\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Accuracy\n",
    "# Accuracy of a linear model can't be calculated, the accuracy is predicted using error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Mean Squared Error\n",
    "print(\"Mean Squared Error:\",mean_squared_error(y_test, y_pred)) # tells you how close a regression line is to a set of points\n",
    "# squaring is necessary to remove any negative signs\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(\"Root Mean Squared Error:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "\n",
    "# R2 Score\n",
    "print(\"R^2 Score:\", r2_score(y_test,y_pred)) # correlation between actual and predicted value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94099634",
   "metadata": {},
   "source": [
    "## Ada Boost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe7a8dd",
   "metadata": {},
   "source": [
    "Ada Boost Regressor begins the process of regression by fitting a regressor on the original dataset and then fits additional copies of the regressor on the same dataset but where the weights of instances are adjusted according to the error of the current prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e183e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a57e91ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataset using make_regression\n",
    "X, y = make_regression(n_samples=200, n_features=20, n_informative=10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0173fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax for creating a Ada Boost Regressor:\n",
    "\n",
    "\n",
    "# AdaBoostRegressor(base_estimator=None, *, n_estimators=50, learning_rate=1.0, loss='linear', random_state=None)\n",
    "\n",
    "# Link for explanation of terms : https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html\n",
    "\n",
    "# A simple model:\n",
    "abr = AdaBoostRegressor(n_estimators=100)\n",
    "abr.fit(X_train, y_train)\n",
    "y_pred = abr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "85b64d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  [[-0.57142553 -1.26969912  0.95187094 ...  0.09052227  0.07042618\n",
      "   0.92036218]\n",
      " [ 0.94864423 -0.7864664  -0.66070123 ...  1.33694277  0.15709528\n",
      "  -1.03124686]\n",
      " [ 0.20123701  2.46201058  0.40123794 ... -1.69042343  0.03389015\n",
      "   0.09193736]\n",
      " ...\n",
      " [ 2.45598562 -1.71291141 -0.03045322 ...  0.0728719   0.25737395\n",
      "   1.00758773]\n",
      " [-0.48985431 -1.05169298  0.42976935 ... -0.03730517  0.74325182\n",
      "  -0.17101863]\n",
      " [-0.92689202  0.53006924  0.36645735 ...  0.32879437 -1.19562272\n",
      "  -0.17951844]]\n",
      "Expected output :  [-5.89316825e+01  9.74688775e+00 -2.06403413e+02  1.90785845e+02\n",
      "  5.74181247e+01  3.20938943e+02 -1.67625224e+02  9.74888291e+01\n",
      " -2.49253863e+01 -6.53086633e+01 -1.02776086e+02 -8.48037131e+01\n",
      " -1.95896175e+01 -1.01367695e+02  3.54922281e+02  3.72602698e+01\n",
      "  1.40806909e+02  2.88981726e+00  3.38023992e+01  1.54381072e+02\n",
      " -1.83761175e+02  1.36716888e+02 -1.27548264e+02  6.00381550e+01\n",
      " -8.03789846e+01  3.52441127e+02 -1.00729899e+02  1.22404145e+02\n",
      "  2.05499871e+01 -1.84562451e+01  1.46073393e+02  5.57682691e+01\n",
      "  1.33641165e+02 -2.45822922e+01  4.79265264e+01  1.31529097e+02\n",
      "  6.06318792e+01  1.14961346e+02  1.69864208e+02  2.22399576e+02\n",
      "  3.45619156e+01 -9.71744942e+01  2.05985400e+01  1.97364501e+01\n",
      "  3.26611162e-01 -5.16685650e+01  7.52198059e+01 -1.84418662e+02\n",
      " -3.66295870e+01 -1.15201224e+02 -1.56708644e+01 -5.40174478e+01\n",
      "  2.17730397e+01 -3.42849665e+01  4.65559791e+01 -1.00767469e+02\n",
      " -4.97254611e+01  6.00944507e+01 -1.03742137e+01 -3.91330098e+01]\n",
      "Predicted output :  [ -48.6272758   -52.53105704  -82.53446833   83.64950868   55.05797091\n",
      "  131.28572114 -154.9183988    83.64950868   39.86268198  -11.75948942\n",
      "   31.55408946  -65.56369845  -66.37719795  -69.9766451   179.48383786\n",
      "   39.0065728    67.67567308   42.16980299   -7.56561186  132.94990411\n",
      "   -7.56561186  103.86682023  -52.53105704   16.29711079   43.61114354\n",
      "  181.82262454  -38.67565696   96.2415358    35.14506607  -85.14382132\n",
      "   79.59678264  -14.69820536   51.23031081  -13.7935927    79.59678264\n",
      "   35.14506607   44.13311294   37.86849819  129.22623964  130.01569623\n",
      "   22.55319227  -42.80075747   29.33130597  -39.70431229  -23.7715334\n",
      "  -75.41332287  -29.42138861  -70.81402333  -64.75884499  -64.75884499\n",
      "    2.82974694   35.14506607   44.13311294  -95.36205223  -15.20032945\n",
      "  -89.38213868  -56.97144083    8.028174    -31.96847912  -43.53033885]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the input & output\n",
    "\n",
    "# Input: A two-dimensional array which contains all the features of the diabetes dataset\n",
    "print(\"Input : \", X_test)\n",
    "\n",
    "# Output: The ouput array is the prediction\n",
    "print(\"Expected output : \", y_test)\n",
    "print(\"Predicted output : \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3ed7aea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 5445.401733704234\n",
      "Root Mean Squared Error: 73.79296534022897\n",
      "R^2 Score: 0.6302924646608671\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Accuracy\n",
    "# Accuracy of a linear model can't be calculated, the accuracy is predicted using error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Mean Squared Error\n",
    "print(\"Mean Squared Error:\",mean_squared_error(y_test, y_pred)) # tells you how close a regression line is to a set of points\n",
    "# squaring is necessary to remove any negative signs\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(\"Root Mean Squared Error:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "\n",
    "# R2 Score\n",
    "print(\"R^2 Score:\", r2_score(y_test,y_pred)) # correlation between actual and predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d7e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
