{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e3ab754",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8463450d",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2061aa",
   "metadata": {},
   "source": [
    "Linear Regression is a linear machine learning model that assumes a linear relationship between the input variables (x) and the single output variable (y). It uses this information to predict the value of y based on the value of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "503b35b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "84814161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "from sklearn.linear_model import LinearRegression #Linear regression package\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "85b5aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing a dataset for linear regression\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "X = boston['data']\n",
    "y = boston['target']\n",
    "# Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f8ef0529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax for creating a Linear Regression model\n",
    "\n",
    "# LinearRegression(*, fit_intercept=True, copy_X=True, n_jobs=None, positive=False)\n",
    "\n",
    "# fit_intercept - calculate the y-intercept of the model\n",
    "# copy_X - Changes the value of x entered in the model\n",
    "# positive - forces the coefficients to be positive\n",
    "\n",
    "#Simple model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a122e49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  [[6.72400e-02 0.00000e+00 3.24000e+00 ... 1.69000e+01 3.75210e+02\n",
      "  7.34000e+00]\n",
      " [9.23230e+00 0.00000e+00 1.81000e+01 ... 2.02000e+01 3.66150e+02\n",
      "  9.53000e+00]\n",
      " [1.14250e-01 0.00000e+00 1.38900e+01 ... 1.64000e+01 3.93740e+02\n",
      "  1.05000e+01]\n",
      " ...\n",
      " [1.68118e+01 0.00000e+00 1.81000e+01 ... 2.02000e+01 3.96900e+02\n",
      "  3.08100e+01]\n",
      " [4.92980e-01 0.00000e+00 9.90000e+00 ... 1.84000e+01 3.96900e+02\n",
      "  4.54000e+00]\n",
      " [2.98500e-02 0.00000e+00 2.18000e+00 ... 1.87000e+01 3.94120e+02\n",
      "  5.21000e+00]]\n",
      "Expected output :  [22.6 50.  23.   8.3 21.2 19.9 20.6 18.7 16.1 18.6  8.8 17.2 14.9 10.5\n",
      " 50.  29.  23.  33.3 29.4 21.  23.8 19.1 20.4 29.1 19.3 23.1 19.6 19.4\n",
      " 38.7 18.7 14.6 20.  20.5 20.1 23.6 16.8  5.6 50.  14.5 13.3 23.9 20.\n",
      " 19.8 13.8 16.5 21.6 20.3 17.  11.8 27.5 15.6 23.1 24.3 42.8 15.6 21.7\n",
      " 17.1 17.2 15.  21.7 18.6 21.  33.1 31.5 20.1 29.8 15.2 15.  27.5 22.6\n",
      " 20.  21.4 23.5 31.2 23.7  7.4 48.3 24.4 22.6 18.3 23.3 17.1 27.9 44.8\n",
      " 50.  23.  21.4 10.2 23.3 23.2 18.9 13.4 21.9 24.8 11.9 24.3 13.8 24.7\n",
      " 14.1 18.7 28.1 19.8 26.7 21.7 22.  22.9 10.4 21.9 20.6 26.4 41.3 17.2\n",
      " 27.1 20.4 16.5 24.4  8.4 23.   9.7 50.  30.5 12.3 19.4 21.2 20.3 18.8\n",
      " 33.4 18.5 19.6 33.2 13.1  7.5 13.6 17.4  8.4 35.4 24.  13.4 26.2  7.2\n",
      " 13.1 24.5 37.2 25.  24.1 16.6 32.9 36.2 11.   7.2 22.8 28.7]\n",
      "Predicted output :  [24.9357079  23.75163164 29.32638296 11.97534566 21.37272478 19.19148525\n",
      " 20.5717479  21.21154015 19.04572003 20.35463238  5.44119126 16.93688709\n",
      " 17.15482272  5.3928209  40.20270696 32.31327348 22.46213268 36.50124666\n",
      " 31.03737014 23.17124551 24.74815321 24.49939403 20.6595791  30.4547583\n",
      " 22.32487164 10.18932894 17.44286422 18.26103077 35.63299326 20.81960303\n",
      " 18.27218007 17.72047628 19.33772473 23.62254823 28.97766856 19.45036239\n",
      " 11.13170639 24.81843595 18.05294835 15.59712226 26.21043403 20.81140432\n",
      " 22.17349382 15.48367365 22.62261604 24.88561528 19.74754478 23.0465628\n",
      "  9.84579105 24.36378793 21.47849008 17.62118176 24.39160873 29.95102691\n",
      " 13.57219422 21.53645439 20.53306273 15.03433182 14.3232289  22.11929299\n",
      " 17.07321915 21.54141094 32.96766968 31.371599   17.7860591  32.75069556\n",
      " 18.74795323 19.21428022 19.41970047 23.08087809 22.87732816 24.06399098\n",
      " 30.52824406 28.71453508 25.90763165  5.17596718 36.8709072  23.76983849\n",
      " 27.26064379 19.25849042 28.41860517 19.3008798  18.94922353 38.00154059\n",
      " 39.44096748 23.72297885 24.83722534 16.52015743 25.9970546  16.73997072\n",
      " 15.48656983 13.52825536 24.12884363 30.76919578 22.18731163 19.8848644\n",
      "  0.42275479 24.86785849 16.05692    17.42486412 25.49798527 22.35171315\n",
      " 32.66562689 22.04428746 27.29799885 23.20302026  6.86196574 14.869251\n",
      " 22.31804948 29.18125768 33.22568234 13.24392523 19.67195771 20.7502616\n",
      " 12.02271319 23.50067006  5.55662571 19.87634689  9.27059783 44.81787339\n",
      " 30.56017983 12.44394048 17.33192202 21.48313292 23.52664913 20.49877266\n",
      " 35.09161099 13.22639935 20.70321163 35.35582833 19.45050576 13.81603561\n",
      " 14.15654562 23.03678503 15.07521258 30.9662041  25.23236632 15.43763716\n",
      " 24.06406534  9.93080346 15.01618901 21.06098873 32.87115732 27.80927747\n",
      " 25.91293794 15.27877362 30.97489404 27.81107682 14.5068157   7.57369946\n",
      " 28.3348068  25.04341153]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the input & output\n",
    "\n",
    "# Input: A two-dimensional array which contains all the features of the boston housing dataset\n",
    "print(\"Input : \", X_test)\n",
    "\n",
    "# Output: The ouput array is the prediction\n",
    "print(\"Expected output : \", y_test)\n",
    "print(\"Predicted output : \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5dd211c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 27.195965766883205\n",
      "Root Mean Squared Error: 5.214975145375403\n",
      "R^2 Score: 0.6733825506400195\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Accuracy\n",
    "# Accuracy of a linear model can't be calculated, the accuracy is predicted using error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Mean Squared Error\n",
    "print(\"Mean Squared Error:\",mean_squared_error(y_test, y_pred)) # tells you how close a regression line is to a set of points\n",
    "# squaring is necessary to remove any negative signs\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(\"Root Mean Squared Error:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "\n",
    "# R2 Score\n",
    "print(\"R^2 Score:\", r2_score(y_test,y_pred)) # correlation between actual and predicted value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d53dfc",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc3168",
   "metadata": {},
   "source": [
    "Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cd1515bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required packages\n",
    "from sklearn.linear_model import LogisticRegression #Logistic regression package\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cbfe7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing a dataset for logistic regression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer[\"data\"]\n",
    "y = cancer['target']\n",
    "#Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "88f46c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Syntax for creating a Logistic Regression model\n",
    "\n",
    "# LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, \n",
    "# intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, \n",
    "# multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "\n",
    "# Link for explanation of terms : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "#Simple model\n",
    "logreg = LogisticRegression(max_iter=3000) \n",
    "logreg.fit(X_train,y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "818db063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  [[1.133e+01 1.416e+01 7.179e+01 ... 1.111e-02 2.758e-01 6.386e-02]\n",
      " [1.263e+01 2.076e+01 8.215e+01 ... 1.105e-01 2.226e-01 8.486e-02]\n",
      " [1.624e+01 1.877e+01 1.088e+02 ... 1.732e-01 2.770e-01 1.063e-01]\n",
      " ...\n",
      " [1.377e+01 1.327e+01 8.806e+01 ... 5.802e-02 2.823e-01 6.794e-02]\n",
      " [9.465e+00 2.101e+01 6.011e+01 ... 6.517e-02 2.878e-01 9.211e-02]\n",
      " [2.327e+01 2.204e+01 1.521e+02 ... 2.346e-01 3.589e-01 9.187e-02]]\n",
      "Expected output :  [1 1 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 1 1\n",
      " 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1\n",
      " 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1\n",
      " 1 1 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0]\n",
      "Predicted output :  [1 1 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1 1 1 1 0 1 1\n",
      " 0 0 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 0 1\n",
      " 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1\n",
      " 1 1 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the input & output\n",
    "\n",
    "# Input: A two-dimensional array which contains all the features of the boston housing dataset\n",
    "print(\"Input : \", X_test)\n",
    "\n",
    "# Output: The ouput array is the prediction\n",
    "print(\"Expected output : \", y_test)\n",
    "print(\"Predicted output : \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6b5976ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score: 0.9707602339181286\n",
      "Mean Squared Error: 0.029239766081871343\n",
      "Root Mean Squared Error: 0.17099639201419234\n",
      "R^2 value 0.8734832790766499\n",
      "Precision: 0.9814814814814815\n",
      "Recall: 0.9724770642201835\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Accuracy\n",
    "# Importing necessary packages\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Accuracy\n",
    "print(\"Test Accuracy Score:\", logreg.score(X_test, y_test)) #Predicted correctly/Total values\n",
    "\n",
    "# Mean Squared Error\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))# tells you how close a regression line is to a set of points\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(\"Root Mean Squared Error:\", mean_squared_error(y_test, y_pred, squared=False)) \n",
    "\n",
    "# R2 Score\n",
    "print(\"R^2 value\", r2_score(y_test,y_pred)) # correlation between actual and predicted value\n",
    "\n",
    "# Precision\n",
    "print(\"Precision:\",precision_score(y_test, y_pred)) #Proportion of positive identifications actually correct\n",
    "\n",
    "# Recall\n",
    "print(\"Recall:\",recall_score(y_test, y_pred)) # Proportion of actual positives was identified correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb4e4a6",
   "metadata": {},
   "source": [
    "## Decision Tree 1 - Iterative Dichotomiser 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6925d85b",
   "metadata": {},
   "source": [
    "A decision tree is a structure that contains nodes (rectangular boxes) and edges(arrows) and is built from a dataset (with rows and columns). Each node is used to make a decision (decision node) or represent an outcome (leaf node)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d70d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required packages\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree Classifier package\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c58d5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing a dataset for Decision Tree 1 - Iterative Dichotomiser 3\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "#Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1f16bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Syntax for creating a Decision Tree 1 - Iterative Dichotomiser 3 model\n",
    "\n",
    "# DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, \n",
    "# min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, \n",
    "# max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0)\n",
    "\n",
    "# Link for explanation of terms : https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "#Simple model\n",
    "dtc = DecisionTreeClassifier(criterion='entropy',max_depth=3)\n",
    "dtc.fit(X_train, y_train)\n",
    "y_pred = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "988d11f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  [[7.2 3.2 6.  1.8]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [6.  3.  4.8 1.8]\n",
      " [5.  3.  1.6 0.2]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [5.7 2.9 4.2 1.3]]\n",
      "Expected output :  [2 0 2 0 1 1 0 1 1 1 2 0 1 1 2 2 0 0 2 1 0 2 1 2 2 1 1 0 1 1 1 2 0 0 0 1 0\n",
      " 1 1 2 2 1 2 0 1]\n",
      "Predicted output :  [2 0 2 0 1 2 0 1 1 1 2 0 1 1 2 1 0 0 2 1 0 2 1 2 2 1 1 0 1 1 1 2 0 0 0 1 0\n",
      " 1 1 2 2 1 2 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the input & output\n",
    "\n",
    "# Input: A two-dimensional array which contains all the features of the boston housing dataset\n",
    "print(\"Input : \", X_test)\n",
    "\n",
    "# Output: The ouput array is the prediction\n",
    "print(\"Expected output : \", y_test)\n",
    "print(\"Predicted output : \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "398268bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score: 0.9555555555555556\n",
      "Mean Squared Error: 0.044444444444444446\n",
      "Root Mean Squared Error: 0.21081851067789195\n",
      "R^2 value 0.9230769230769231\n",
      "Precision: 0.9555555555555556\n",
      "Recall: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Accuracy\n",
    "# Importing necessary packages\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Accuracy\n",
    "print(\"Test Accuracy Score:\", dtc.score(X_test, y_test)) #Predicted correctly/Total values\n",
    "\n",
    "# Mean Squared Error\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))# tells you how close a regression line is to a set of points\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(\"Root Mean Squared Error:\", mean_squared_error(y_test, y_pred, squared=False)) \n",
    "\n",
    "# R2 Score\n",
    "print(\"R^2 value\", r2_score(y_test,y_pred)) # correlation between actual and predicted value\n",
    "\n",
    "# Precision\n",
    "print(\"Precision:\",precision_score(y_test, y_pred, average='weighted')) #Proportion of positive identifications actually correct\n",
    "\n",
    "# Recall\n",
    "print(\"Recall:\",recall_score(y_test, y_pred, average='weighted')) # Proportion of actual positives was identified correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39efa7fc",
   "metadata": {},
   "source": [
    "## Decision Tree - CART (Classification and Regression Tree Algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8166a633",
   "metadata": {},
   "source": [
    "A classification algorithm for building a decision tree based on Gini's impurity index as splitting criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9e7dd783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required packages\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree Classifier package\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "59352dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing a dataset for Decision Tree 2 - CART\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "#Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d08c3e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Syntax for creating a Decision Tree 1 - Iterative Dichotomiser 3 model\n",
    "\n",
    "# DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, \n",
    "# min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, \n",
    "# max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0)\n",
    "\n",
    "# Link for explanation of terms : https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "#Simple model\n",
    "dtc_gini = DecisionTreeClassifier(criterion='gini',max_depth=3)\n",
    "dtc_gini.fit(X_train, y_train)\n",
    "y_pred = dtc_gini.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c935751c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  [[6.3 2.8 5.1 1.5]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.  3.  4.8 1.8]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [6.2 2.2 4.5 1.5]]\n",
      "Expected output :  [2 1 1 1 2 0 0 2 1 2 2 1 0 0 2 2 1 0 0 2 0 2 1 0 0 1 1 2 2 2 0 0 0 1 0 1 2\n",
      " 2 2 1 0 2 2 2 1]\n",
      "Predicted output :  [1 1 1 1 2 0 0 2 1 2 2 1 0 0 2 1 1 0 0 2 0 2 1 0 0 1 1 2 2 2 0 0 0 1 0 1 2\n",
      " 2 1 1 0 2 2 2 1]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the input & output\n",
    "\n",
    "# Input: A two-dimensional array which contains all the features of the boston housing dataset\n",
    "print(\"Input : \", X_test)\n",
    "\n",
    "# Output: The ouput array is the prediction\n",
    "print(\"Expected output : \", y_test)\n",
    "print(\"Predicted output : \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9e2b28fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score: 0.9555555555555556\n",
      "Mean Squared Error: 0.06666666666666667\n",
      "Root Mean Squared Error: 0.2581988897471611\n",
      "R^2 value 0.9051966292134831\n",
      "Precision: 0.9458333333333333\n",
      "Recall: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Accuracy\n",
    "# Importing necessary packages\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Accuracy\n",
    "print(\"Test Accuracy Score:\", dtc.score(X_test, y_test)) #Predicted correctly/Total values\n",
    "\n",
    "# Mean Squared Error\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))# tells you how close a regression line is to a set of points\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(\"Root Mean Squared Error:\", mean_squared_error(y_test, y_pred, squared=False)) \n",
    "\n",
    "# R2 Score\n",
    "print(\"R^2 value\", r2_score(y_test,y_pred)) # correlation between actual and predicted value\n",
    "\n",
    "# Precision\n",
    "print(\"Precision:\",precision_score(y_test, y_pred, average='weighted')) #Proportion of positive identifications actually correct\n",
    "\n",
    "# Recall\n",
    "print(\"Recall:\",recall_score(y_test, y_pred, average='weighted')) # Proportion of actual positives was identified correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd66b16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
